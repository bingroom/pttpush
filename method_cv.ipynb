{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/joekaojoekao/PycharmProjects/push/github/dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from /Users/joekaojoekao/PycharmProjects/push/github/dict.txt.big ...\n",
      "Loading model from cache /var/folders/qn/v8s1xx6d7qgclyhkk1t701zc0000gn/T/jieba.u28e5fd167ca6b25e789769ad04c48668.cache\n",
      "DEBUG:jieba:Loading model from cache /var/folders/qn/v8s1xx6d7qgclyhkk1t701zc0000gn/T/jieba.u28e5fd167ca6b25e789769ad04c48668.cache\n",
      "Loading model cost 1.89216423035 seconds.\n",
      "DEBUG:jieba:Loading model cost 1.89216423035 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "999\n",
      "718\n",
      "['heavenkghs', 'nysky', 'quiet113', 'john2557', 'duo0518', 'tienhun', 'joyjack', 'vm9487', 'aftersilence', 'lingon', 'toshizo', 'yuminlin', 'fhuocrkt', 'theropod', 'kkchen', 'emptie', 'h3178378', 'zxc12385', 'Amelie27', 'buddygirl', 'chiang017', 'fromwilda', 'carters', 'Magicwind', 'glory5566', 'feather9298', 'fjdkqp', 'cojinyu', 'gayya152535', 'hnrywang', 'bugya', 'JeanSijhih', 'joyjcc', 'jeffl0402', 'Valerie06', 'SpadeR', 'cloud0528', 'xup654vu06', 'kindless', 'mylife001', 'minnie', 'ronanhuang', 'tako0988', 'treiss', 'asami', 'mineko', 'dayoa', 'akaihuang', 'sigh0602', 'wolfking623', 'koreapig5566', 'lachesis1980', 'handsomecat', 'JCS15', 'caffeine34ko', 'pprisa', 'Nick7777', 'Voldemar', 'samuelcdf', 'jaguars33', 'chx64', 'otom', 'hiro1221', 'hyde7015', 'wxtab019', 'deleteBB', 'WhyNoSmoke', 'lovemelynn', 'straight0711', 'allen5339', 'q152134', 'Sugiros', 'ursula141885', 'Monchestnut', 'captainlee', 'hoka777', 'chind', 'kaorucyc', 'surot', 'TheMiserable', 'motorolla', 'aadm', 'benson', 'colan8', 'oscar1982law', 'a0913', 'emilyluvsptt', 'Vipasyin', 'ABC9D', 'w3160828', 'cat5672', 'queue', 'gogogo12321', 'kevinptt', 'cancer0708', 'robertchun', 'neo77', 'jennywalk', 'YesGG', 'ALLYJJ2599', 'C4891', 'CHISN', 'dape321', 'morgan168', 'ccab99', 'stero', 'W96U', 'ilikebulldog', 'lordforce', 'pinkchi', 'pita30', 'seashel', 'TurTao', 'bismarcp', 'vyjssm', 'WalkFish', 'yandin', 'chachameow', 'CrazyKill', 'rufjvm12345', 'nicest', 'orz151426', 'lo23', 'ittie', 'Automatic620', 'Leaves827', 'Meow0129', 'hydeaya', 'forRITZ', 'alentek', 'roxcido', 'hiphopphysic', 'RLH', 'iloveshida', 'xyz2', 'yovven', 'rookiebear', 'arhuro', 'genka', 'a129517496', 'codehard', 'qaz963747', 'TaTa5566', 'ahao1105', 'caesar119', 'coolwind4410', 'foxfox1017', 'pppeeeppp', 'purplebfly', 'pennymarkfox', 'VoyagerKid', 'Allen0315', 'comjj45', 'sukisam', 'qkenny', 'y5gogogo', 'fcu6969', 'hicker', 'libraayu', 'badbadook', 'awoorog', 'shinjyeh', 'tooeasy', 'rabbit83035', 'wt5665', 'bewiiarro', 'pljck', 'BiBiG', 'haijin', 'omegajoker', 'coolfuc', 'asterisk0213', 'deepmilk', 'hot5566', 'HNO3', 'yangnana', 'ai4zo', 'Karajan8305', 'HAHAHUNG', 'JJLi', 'Nerv', 'FIRZEN45', 'wanying', 'liiiiiiiio', 'wolver', 'LIONDODO', 'lupolewis', 'airstation', 'matthew0123', 'luxifer', 'signm', 'crazycomet', 'AAAC', 'AAAB', 'AAAD', 'li751012', 'aoiaoi', 'southring', 'andy80209', 'u831208', 'alyce36', 'for103you', 'coolman123', 'jdemon', 'jil', 'Azu', 'destroyed', 'BlueJet0501', 'uok', 'herman602', 'bc1007', 'zaqmkovfr', 'miniamigo', 'wilsonno1', 'KTA0619', 'DarkKnight', 'liangmei', 'douglasyeh', 'liao18', 'kiki2125', 'sleepybaby', 'tivoli0315', 'Yakyuboy51', 'shhh', 'ph4586', 'Akaiito', 'NTRyourwife', 'hickory', 'TAKIHERO', 'pilot1982', 'sasamotorena', 'ninashu73121', 'nacciabe', 'a23633302', 'hirokofan', 'qzp5408', 's952112', 'nanie', 'traystien', 'staroceanj9', 'liyimu', 'gotohikaru', 'Mchord', 'erixerix', 'hillkoko', 'showken', 'hem0207', 'yoyoman0529', 'justin9012', 'lovesuicide', 'adapt', 'ronlai', 'chifu', 'e04su3fn3', 'FTKBOYS', 'melidy', 'ri', 'Tmgy', 'Safin', 'chivalry70', 'wht810090', 'ckshchen', 'newstarting', 'mykuririn', 'jane26thmix', 'zxcvf', 'GodsRevival', 'james780909', 'SundayRose', 'casperrrr', 'rca0621', 'goldman0204', 'hamel', 'benboman', 'liyuoh', 'wowisgood', 'weifish', 'hapteasing', 'bpooqd', 'biglafu', 'finzaghi', 'hankwu', 'hb000', 'tn00706223', 'genius0716', 'niceright', 'hohaiyanyan', 'nobeldd', 'meaning12', 'a1341150854', 'catbuji', 'Fezico', 'jelly1128', 'john07', 'looop', 'supermars', 'lauly', 'akimiyavi', 'HOWARDSHEN', 'snian', 'qwaqwa2007', 'rotusea', 'heisego', 'YOYOGIVEME', 'hydralee', 'wangisiung', 'hownever', 'daleleu', 'jyue', 'ainosei', 'iamursis', 'happyqaz', 'zhvul3u4', 'ryokoon', 'stilllove56', 'heptachord', 'edu94848325', 'YumingHuang', 'rainingdayz', 'dannyxm3', 'opjinshan', 'icead', 'wl1451226', 'nzj', 'DEUT', 'cherish772', 'fresheasy', 'BeefNoodles', 'jokywolf', 'doom3', 'freeway11', 'TheJ', 'WatanabeKen', 'newjackle', 'wallowes', 'yuhurefu', 'grahamwu', 'catdreaming', 'everoh99', 'catvsdog', 'kaojet', 'RaHarakhte', 'JPMontoya', 'charlie0531', 'guesttseug', 'eljin', 'zop', 'nfish', 'goodman', 'applejone', 'Invec', 'kontrollCat', 'GreenScatter', 'ZMittermeyer', 'keithking', 'taiwanwang', 'jeans520', 'breadflower', 'wujason', 'BBBBBBBB', 'sluttysavage', 'omaha', 'hollowyears', 'jessicakard', 'SNGoMMX', 'shippai', 'lockgolden', 'mia3', 'ATONG25', 'phix', 'lunlun0802', 'yule1224', 'blackteasart', 'a9wh61ks', 'nelljin', 'Infernity', 'jopyt', 'ioupoiu', 'doras', 'MiniiH', 'JoyceSmile', 'erptt', 'asukace', 'chosenone', 'blacktea5566', 'lepidoptera', 'Barquinho', 'makapaka', 'cappin', 'cyswu', 'gg123sf', 'QUEENSUSAN', 'hsgreent', 'mailismine', 'yozeng', 'm0630821', 'longmok2500', 'Ga11ardo', 'pppttt', 'Terrykho', 'ariesw', 'jknm0510a', 'raxy', 'a22363491', 'MaRiaNi', 'rythem', 'tsaiyilun307', 'olgas', 'ddlnm', 'toro736', 'Biganan', 'punksion', 'awer89', 'FatDaniel', 'bigheadpro', 'HenryTudor', 'Bookdaily', 'will8149', 'jabari', 'Gnome', 'teaplus', 'josLynYa', 'tume7', 'cpuds', 'xul327', 'MAGGIE99', 'sunface', 'asbbey', 'wildgoat', 'AMPHIBIA', 'cappa', 'liam5184910', 'Darvish816', 'rogergon', 'tfoasy', 'zainlove', 'girl10319', 'best2008', 'ams9', 'ImMACACO', 'tsaiyunlung', 'VGA', 'jkasc28s', 'probsk', 'q224222', 'airflow', 'moocow', 'cwjing', 'gmkuo', 'baby1022', 'mobile02', 'jasonrod05', 'howdiee', 'nfstako', 'olli', 'Kay731', 'Dusha', 'adoken', 'ollo', 'underload', 'dodonpachi', 'blackcellar', 'sheng3476', 'kirby0415', 'mayurina', 'Smile365Day', 'b0d', 'EV1L', 'a2629397', 'lomgray', 'iosian', 'pradalove', 'nipon0208', 'Vett', 'jack33', 'canser', 'blackcateva', 'kobejo4', 'GoodElephant', 'sggs', 'typekid', 'Gloom666', 'regun', 'creulfact', 'majanliu', 'jimli', 'wk105', 'ID556', 'shena30335', 'MortalCGU', 'smpian', 'CO2', 'aerymani', 'tn00210585', 'stemcell', 'zzj11', 'S80', 'flyinwind828', 'eeee111', 'swordfish217', 'APPLEin5566', 'osak', 'LakeBodom', 'andersontom', 'yukina23', 'henrry60109', 'xian', 'sean60106', 'eterbless', 'ryan0222', 'ChosYon', 'hanhsiangmax', 'ascii', 'saeea', 's4340392', 'koriras', 'aurorax', 'mit28', 'lilieye', 'crossover103', 'yTim5566', 'maxdi', 'ciplu', 'yjchiou', 'manmanhuang', 'shiva999', 'miyuika', 'zenixls2', 'purpose', 'XVN', 'oscar721', 'kula77', 'phil1984', 'cain07', 'stfang925', 'rangting', 'batt0512', 'Hans14', 'DarkerWu', 'STEVENUA', 'rock666', 'ymca900', 'asukaka', 'jenny830913', 'benza', 'hihisnoopy', 'enoeno', 'arsure666', 'didolydia', 'jojoSpirit', 'ohmickey', 'iceworld25', 'appleswill', 'vjuko', 'ncnuboy', 'groundmon', 'gn780802', 'CORSA', 'Marino', 'ichbinsarah', 'flowersuger', 'ufoon', 'louis5265', 'itsmyspirit', 'Invincibleme', 'teddygoodgoo', 'anoreader', 'yragggc', 'Miseryz', 'oneyear', 'istay', 'q13461346', 'kissbin', 'Tenging', 'Sousake', 'a710689', 'bced', 'cashayoung', 'larrysu', 'cofc', 'EN23', 'CTgogogo', 'homerunball', 'oeibei', 'Hall', 'marques', 'vdan', 'fukobe', 'jplo', 'rettttt5', 'diego99', 'coolwei', 'hanklun', 'shenasu', 'yuyuyou', 'pttdoris', 'LUB500', 'jmrla', 'RHTZ', 'kakaman', 'redstone', 'terry456', 'eric61446', 'kiddno56979', 'pz5202', 's1020824', 'handfoxx', 'johnny3', 'scottlsw', 'qqu7799tw', 'newwu', 'unclefucka', 'eddy1221', 'dakook', 'heloiselu', 'goetze', 'MattiaPasini', 'Akhenaten', 'u5710587', 'meowzilla', 'V6WOLF', 'RPedsel', 'et803', 'ysk999', 'takepron', 'toy812', 'johnnyd', 'boy00225', 'Kakehiko', 'poemking', 'southboy', 'ACrimsonTide', 'pomelo524', 'ariel0912', 'lucef', 'acer758219', 'poipoi882002', 'machida', 'crazymome', 'rock123520', 'zeta731115', 'antje1211', 'rusa', 'bjj', 'liebes', 'ZEALOTGO', 'addycat', 'itrs821', 'atom1130', 'maggiekiki', 'xx60824xx', 'izacc', 'sunkis6842', 'iMANIA', 'cuckooflower', 'opthr1215', 'Leepofeng', 'Carmelo3', 'yaya', 'Amadeus1008', 'diefox', 'Feuerbach', 'peiring', 'luciffar', 'appovoa', 's1385999', 'a1038874', 'longlyplant', 'yun3liu', 'eitingirl', 'MasCat', 'HIRU', 'BlackBass', 'julia66', 'AQUANGEL', 'puec2', 'bimmer3', 'snow71412', 'minan', 'popy8789', 'zankarasu', 'KOBER81', 'ohmygod0707', 'benjaminchia', 'creak', 'testmac', 'WeAntiTVBS', 'MagicMoney', 'vovzz', 'setraise', 'chucky', 'yogi', 'rs6000', 'REALLYLIFE', 'fansboy', 'wild2012', 'gaiaesque', 'sunnywei', 'fst1985', 'sorryfly', 'dodokevin', 'slx54461', 'iamOsaka', 'ytall', 'daidai', 'sizhen', 'lulumic', 'eva617266', 'hsinwen', 'mmpercussion', 'whiterM', 'kingdef', 'Cheese27', 'lch2011', 'euphoria01', 'sobadwhos', 'jack0204', 'excel5566']\n",
      "total word 11450\n",
      "stop word 295\n",
      "rare word 7028\n",
      "num_word: 1 \t152\n",
      "num_word: 2 \t133\n",
      "num_word: 3 \t7\n",
      "num_word: 4 \t2\n",
      "num_word: 5 \t1\n",
      "295\n",
      "295\n",
      "295\n",
      "total word 11508\n",
      "stop word 294\n",
      "rare word 7144\n",
      "num_word: 1 \t149\n",
      "num_word: 2 \t134\n",
      "num_word: 3 \t8\n",
      "num_word: 4 \t2\n",
      "num_word: 5 \t1\n",
      "294\n",
      "294\n",
      "294\n",
      "total word 11619\n",
      "stop word 302\n",
      "rare word 7200\n",
      "num_word: 1 \t151\n",
      "num_word: 2 \t140\n",
      "num_word: 3 \t8\n",
      "num_word: 4 \t2\n",
      "num_word: 5 \t1\n",
      "302\n",
      "302\n",
      "302\n"
     ]
    }
   ],
   "source": [
    "##import processed push data\n",
    "\n",
    "#/Users/joekaojoekao/PycharmProjects/push/github/visualized/select_pushes1000_1.txt\n",
    "with open('/Users/joekaojoekao/PycharmProjects/push/github/visualized/select_pushes1000_1.txt', 'rb') as fin:\n",
    "    s = fin.read().split('\\n')\n",
    "    lines = []\n",
    "    for line in s:\n",
    "        lines.append(line.split('\\t'))\n",
    "    fin.close()\n",
    "\n",
    "sample_dict = {}\n",
    "for i in lines:\n",
    "    \n",
    "    #print len(i)\n",
    "    #if len(i) >= 3:\n",
    "    if len(i) != 2:\n",
    "        continue\n",
    "    uid = i[0]\n",
    "    push = i[1]\n",
    "    if uid not in sample_dict:\n",
    "        sample_dict[uid] = [push]\n",
    "    else:\n",
    "        sample_dict[uid].append(push)\n",
    "#print sample_dict\n",
    "\n",
    "\n",
    "##segment pushes\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "jieba.analyse.set_stop_words('stopword_pool/merged_stopword.txt')\n",
    "\n",
    "sample_dict_jieba = {}\n",
    "for uid in sample_dict.keys():\n",
    "    pushes = sample_dict[uid]\n",
    "    if len(pushes) > 0:\n",
    "        sample_dict_jieba[uid] = []\n",
    "        for push in pushes:\n",
    "            seg_list = list(jieba.cut(push, cut_all=False))\n",
    "            sample_dict_jieba[uid].append((push,seg_list))\n",
    "#從ptt push開始處理\n",
    "#我要uid:push&trunked word\n",
    "#幹 要現切 因為產生的東西只剩uid+push(無順序無法查)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "#set gt_numword (meaningful), gt_numpush (active)\n",
    "NUM_WORD_GT = 4\n",
    "NUM_PUSH_GT = 3 #for 6 fold-cv\n",
    "\n",
    "new_pushes = {}\n",
    "for k in sample_dict.keys():\n",
    "    gt_push = [x for x in sample_dict[k] if len(x) > NUM_WORD_GT]\n",
    "    if len(gt_push) > 0:\n",
    "        new_pushes[k] = gt_push\n",
    "\n",
    "user_list = []\n",
    "for k in new_pushes.keys():\n",
    "    if len(new_pushes[k]) >= NUM_PUSH_GT:\n",
    "        user_list.append(k)\n",
    "        \n",
    "print len(sample_dict)\n",
    "print len(new_pushes)\n",
    "print len(user_list)\n",
    "print user_list\n",
    "\n",
    "#import nltk\n",
    "from sklearn import cross_validation\n",
    "#training_set = nltk.classify.apply_features(extract_features, documents)\n",
    "#dict_user = {} #training\n",
    "#dict_user_ans = {} #testing\n",
    "CV_TIMES = 3\n",
    "\n",
    "#list_user = [{}] * 3\n",
    "#list_user_ans = [{}] * 3\n",
    "\n",
    "list_user = [{} for i in range(3)] \n",
    "list_user_ans = [{} for i in range(3)] \n",
    "\n",
    "\n",
    "for uid in user_list:\n",
    "    training_set = sample_dict_jieba[uid]\n",
    "    #cv = cross_validation.KFold(len(training_set), n_folds=3, indices=True, shuffle=False, random_state=None, k=None)\n",
    "    #trainset = [0,1,2,3,4,5,6,7,8,9]\n",
    "    cv = cross_validation.ShuffleSplit(len(training_set), n_iter=CV_TIMES, test_size=0.33) # 2/3 for train, 1/3 for test, do 3 times  \n",
    "    \n",
    "    #for i in training_set:\n",
    "        #print i[0]\n",
    "    \n",
    "    for n, (traincv, testcv) in enumerate(cv): #每個user都有3組cv的推文\n",
    "        #print n, traincv, testcv\n",
    "        \n",
    "        train_list = [training_set[i] for i in traincv]\n",
    "        test_list = [training_set[i] for i in testcv]\n",
    "        \n",
    "#         for i in zip(*train_list)[0]:\n",
    "#             print i\n",
    "#         print '---'\n",
    "#         for i in zip(*test_list)[0]:\n",
    "#             print i\n",
    "        \n",
    "        list_user[n][uid] = train_list\n",
    "        list_user_ans[n][uid] = test_list\n",
    "        \n",
    "#         list_user[n][uid] = []\n",
    "#         for i in traincv:\n",
    "#             list_user[n][uid].append(training_set[i]) #list_user[第n次cv][user uid]\n",
    "        \n",
    "#         list_user_ans[n][uid] = []\n",
    "#         for i in testcv:\n",
    "#             list_user_ans[n][uid].append(training_set[i])\n",
    "        \n",
    "        #print uid\n",
    "        #for v in list_user[0][uid]:\n",
    "            #print v[0]\n",
    "            #for vv in v:\n",
    "                #print vv[0]\n",
    "\n",
    "\n",
    "# for p in list_user[0].values()[1]:\n",
    "#     for pp in p:\n",
    "#         print p[0]\n",
    "# print '-----------'\n",
    "# for p in list_user[1].values()[1]:\n",
    "#     for pp in p:\n",
    "#         print p[0]\n",
    "\n",
    "# real do cv \n",
    "final_list = []\n",
    "\n",
    "for i in xrange(CV_TIMES):\n",
    "    dict_user = list_user[i]\n",
    "    dict_user_count = pttfunc.count_dict(dict_user) #count the freq\n",
    "    \n",
    "    dict_user_ans = list_user_ans[i]\n",
    "    dict_user_count_ans = pttfunc.count_dict(dict_user_ans) #count the freq for ans(test)\n",
    "    from collections import Counter\n",
    "    count_all = Counter()\n",
    "    for v in dict_user_count.values():\n",
    "        count_all += Counter(v)\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    dict_all_count = OrderedDict(sorted(dict(count_all).items(), key=lambda t: t[1], reverse=True))\n",
    "\n",
    "    ##gen sw\n",
    "    word = dict_all_count.keys()\n",
    "    W_PERCENT = 0.025 #0.025\n",
    "    ## setting for stopword & rareword percentage\n",
    "    stopwords = [x for x in word if dict_all_count[x] >= dict_all_count[word[int(len(word) * W_PERCENT)]]]\n",
    "    rarewords = [x for x in word if dict_all_count[x] <= dict_all_count[word[int(len(word) * (1-W_PERCENT))]]] #0.975\n",
    "\n",
    "    ## stop word list\n",
    "    sw_list = [x for x in stopwords] \n",
    "    ## rare word list\n",
    "    rw_list = [x for x in rarewords] \n",
    "    print 'total word', len(word)\n",
    "    print 'stop word', len(sw_list)\n",
    "    print 'rare word', len(rw_list)\n",
    "\n",
    "\n",
    "    sw_count_dict = {}\n",
    "    for w in sw_list:\n",
    "        sw_count_dict.setdefault(len(w),[]).append(w)\n",
    "\n",
    "\n",
    "    K_NUMWORD = 6\n",
    "    selected_sw = []\n",
    "    for k in sw_count_dict.keys()[0:K_NUMWORD]:\n",
    "        print 'num_word:',k,'\\t',len(sw_count_dict[k])\n",
    "        selected_sw += sw_count_dict[k]\n",
    "    print len(selected_sw)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##gen vec\n",
    "    import itertools\n",
    "    general_vec = {}\n",
    "    for uid in user_list: # for each user id\n",
    "        user_len = sum([len(x) for x in dict_user_count[uid]]) #total word freq\n",
    "        #print sum(v.values())\n",
    "        if user_len > 0:\n",
    "            #vec = [jvc_grams_count[idx].get(w, 0) for w in new_sw_list] #stopword without function words\n",
    "\n",
    "            vec = [dict_user_count[uid].get(w, 0) for w in selected_sw]\n",
    "            g_vec = [float(x) / user_len for x in vec]\n",
    "            general_vec[uid] = g_vec\n",
    "\n",
    "\n",
    "    general_vec_ans = {}\n",
    "    for uid in user_list: # for each user id\n",
    "        user_len = sum([len(x) for x in dict_user_count_ans[uid]]) #total word freq\n",
    "        #print sum(v.values())\n",
    "        if user_len > 0:\n",
    "            #vec = [jvc_grams_count[idx].get(w, 0) for w in new_sw_list] #stopword without function words\n",
    "\n",
    "            vec = [dict_user_count_ans[uid].get(w, 0) for w in selected_sw]\n",
    "            g_vec = [float(x) / user_len for x in vec]\n",
    "            general_vec_ans[uid] = g_vec\n",
    "\n",
    "    print len(general_vec[user_list[0]])\n",
    "    print len(general_vec_ans[user_list[0]])\n",
    "    \n",
    "    import pttfunc\n",
    "    #comb = gb.getCombination(len(user_list))\n",
    "\n",
    "    ##calculate similarity for each user pair\n",
    "\n",
    "    sim_list = np.array((0.0, 0.0, 0.0))\n",
    "\n",
    "    # for i, j in comb:\n",
    "    #     wj_sw = pttfunc.weighted_jaccard(general_vec[user_list[i]], general_vec_ans[user_list[j]])\n",
    "    #     #sim_list = np.append(sim_list, np.array((k1, k2, wj_sw), dtype=mtype))\n",
    "    #     sim_list = np.vstack((sim_list, np.array((round(float(i),1), round(float(j),1), wj_sw))))\n",
    "\n",
    "    for i in xrange(len(user_list)):\n",
    "        for j in xrange(len(user_list)):\n",
    "            wj_sw = pttfunc.weighted_jaccard(general_vec[user_list[i]], general_vec_ans[user_list[j]])\n",
    "            sim_list = np.vstack((sim_list, np.array((round(float(i),1), round(float(j),1), wj_sw))))\n",
    "\n",
    "\n",
    "\n",
    "    sim_list = sim_list[1:]\n",
    "    sim_list = sim_list[sim_list[:,2].argsort()]\n",
    "    sim_list = sim_list[::-1]\n",
    "\n",
    "\n",
    "\n",
    "    user_sim_list = []\n",
    "    for i, j, sim in sim_list:\n",
    "        user_sim_list.append((user_list[int(i)], user_list[int(j)] + 'ANS', sim))\n",
    "    \n",
    "    final_list.append(user_sim_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.29\n",
      "my_precision: 0.0709861838971\n",
      "my_recall: 0.207520891365\n",
      "f-1 measure: 0.10578629748\n"
     ]
    }
   ],
   "source": [
    "from IPython.html.widgets import interact\n",
    "def evaluate(thres_sim, cv_index):\n",
    "    \n",
    "    user_sim_list = final_list[cv_index]\n",
    "    ans_pair_lt_thres = 0 #same user & LT\n",
    "    user_pair_lt_thres = 0 # LT\n",
    "    num_user = len(user_list)\n",
    "    \n",
    "    \n",
    "    sim_list = zip(*user_sim_list)[2]\n",
    "    sim_list = [value for value in sim_list if not math.isnan(value)]\n",
    "    max_thres = max(sim_list)\n",
    "    print max_thres\n",
    "    print thres_sim\n",
    "    if thres_sim > max_thres:\n",
    "        return\n",
    "    \n",
    "    for i,j,sim in user_sim_list:\n",
    "        if i in j and sim >= thres_sim:\n",
    "            ans_pair_lt_thres += 1\n",
    "        if sim >= thres_sim:\n",
    "            user_pair_lt_thres += 1\n",
    "        \n",
    "    #b = len(user_list)\n",
    "    precision = float(ans_pair_lt_thres) / user_pair_lt_thres\n",
    "    recall = float(ans_pair_lt_thres) / num_user\n",
    "    print 'my_precision:', precision #how many user their ACC are larger than Thres\n",
    "    print 'my_recall:', recall\n",
    "    if precision == 0 and recall == 0:\n",
    "        return\n",
    "    print 'f-1 measure:', 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interact(evaluate, thres_sim=(0.0,1.0,0.01), cv_index=(0, CV_TIMES-1)); #101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8\n",
      "my_precision: 0.4\n",
      "my_recall: 0.00278551532033\n",
      "f-1 measure: 0.00553250345781\n"
     ]
    }
   ],
   "source": [
    "interact(evaluate, thres_sim=(0.0,1.0,0.01), cv_index=(0, CV_TIMES-1)); #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/joekaojoekao/PycharmProjects/push/github/result/'\n",
    "prefix = '1000_1'\n",
    "for i in xrange(CV_TIMES):\n",
    "    fout = open(path+prefix+'_cv_'+str(i)+'.txt', 'wb')\n",
    "    user_sim_list = final_list[i]\n",
    "    for i,j,sim in user_sim_list:\n",
    "        fout.write(str(i)+','+str(j)+','+str(sim)+'\\n')\n",
    "    fout.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akaihuang', 'jennywalk', 'C4891', 'morgan168', 'AAAB', 'AAAD', 'fst1985', 'aoiaoi', 'andy80209', 'fhuocrkt', 'wxtab019', 'keithking', 'wilsonno1', 'douglasyeh', 'Meow0129', 'chind', 'motorolla', 'Yakyuboy51', 'feather9298']\n",
      "361\n",
      "(nan, nan, 0.6901408450704225, 0.66666666666666663, 0.66666666666666663, 0.63157894736842102, 0.61111111111111105, 0.57142857142857151, 0.55944477972238982, 0.55174534830078426, 0.53546375681995317, 0.48845686512758191, 0.44829325710442236, 0.44177126917712689, 0.44055068836045042, 0.42707444864140376, 0.42548596112311021, 0.42352941176470593, 0.42227378190255205, 0.42191142191142189, 0.42120503396814796, 0.41607898448519043, 0.40935672514619881, 0.40772128060263652, 0.40271493212669679, 0.39919354838709681, 0.39466019417475723, 0.39160839160839161, 0.39006024096385539, 0.38819617622610131, 0.38317757009345793, 0.38129496402877705, 0.36966126656848308, 0.36641221374045796, 0.36268786486150795, 0.35506929248723568, 0.35077288941736023, 0.34768541562966659, 0.34759976865240028, 0.34482758620689646, 0.34207240948813983, 0.33333333333333337, 0.33142639206712438, 0.32859281437125742, 0.32786885245901626, 0.32565789473684215, 0.3222543352601156, 0.31904761904761908, 0.31896551724137934, 0.31578947368421051, 0.31001371742112488, 0.29723837209302323, 0.29551820728291328, 0.29550209205020922, 0.29011786038077964, 0.28599221789883272, 0.2843355605048255, 0.28195345288057988, 0.28000000000000003, 0.27904301817345295, 0.27777777777777773, 0.27450980392156865, 0.27443609022556392, 0.27272727272727271, 0.27142857142857135, 0.26996805111821087, 0.26992287917737789, 0.26826029216467462, 0.2678571428571429, 0.2653399668325041, 0.26403326403326405, 0.26132404181184671, 0.26113671274961597, 0.25920245398773001, 0.2576419213973799, 0.25641025641025644, 0.25609756097560971, 0.25430737422467264, 0.25, 0.25, 0.24867724867724864, 0.24355300859598844, 0.24324324324324331, 0.24177505738332059, 0.24137931034482757, 0.24127906976744184, 0.24122137404580152, 0.24107142857142858, 0.23975409836065578, 0.23928944618599793, 0.2378854625550661, 0.23134210109332909, 0.23120973514674295, 0.23030018761726079, 0.2270054598908022, 0.22620519159456112, 0.22580645161290319, 0.22444183313748528, 0.2243221035332785, 0.22347986312187423, 0.22222222222222221, 0.22147651006711411, 0.22087813620071678, 0.22048929663608566, 0.21883005977796754, 0.2168674698795181, 0.21538461538461537, 0.21491228070175439, 0.21477272727272725, 0.21428571428571425, 0.21072796934865898, 0.20924439523941324, 0.2087912087912088, 0.20743034055727549, 0.20736589271417136, 0.20734126984126983, 0.20663650075414783, 0.20345059377100608, 0.20312499999999997, 0.20152671755725185, 0.20041322314049589, 0.19951040391676864, 0.1994609164420485, 0.19726027397260273, 0.1967930029154519, 0.19620253164556956, 0.19077568134171904, 0.189873417721519, 0.18972001671541996, 0.18805970149253734, 0.18796992481203006, 0.18609406952965232, 0.18503674014696059, 0.1846153846153846, 0.18433179723502305, 0.18414322250639387, 0.18352272727272728, 0.18227933716604666, 0.18002236302646291, 0.17961081453418287, 0.17948717948717946, 0.17940199335548171, 0.17532467532467533, 0.17266851338873498, 0.17212249208025351, 0.16927899686520376, 0.16904962153069811, 0.16893203883495145, 0.1674107142857143, 0.16666666666666666, 0.16611295681063123, 0.16442953020134229, 0.16328708644610457, 0.16296296296296292, 0.16216216216216212, 0.16199478487614077, 0.15965051628276411, 0.15953157995776537, 0.15739268680445154, 0.15517241379310343, 0.15384615384615383, 0.15338645418326693, 0.15037593984962405, 0.14999999999999997, 0.14778325123152708, 0.14743049705139002, 0.14730447987851183, 0.14598540145985398, 0.14335260115606938, 0.141396933560477, 0.13822894168466521, 0.13743842364532019, 0.1373926619828259, 0.13661202185792345, 0.1348107109879963, 0.13439752832131824, 0.13333333333333333, 0.1333333333333333, 0.13253012048192772, 0.13253012048192769, 0.13235294117647059, 0.13095238095238096, 0.1309192200557103, 0.13030831878999419, 0.12943469785575049, 0.12846865364850973, 0.12676056338028169, 0.12457337883959044, 0.12404836542767579, 0.12355848434925865, 0.12195121951219509, 0.12101390024529846, 0.12091503267973855, 0.12080536912751678, 0.12011517893870834, 0.11784675072744909, 0.11578947368421053, 0.11508951406649619, 0.11398963730569948, 0.11247443762781187, 0.11221945137157105, 0.10791366906474824, 0.10588235294117647, 0.10444874274661509, 0.10414746543778801, 0.10344827586206896, 0.10344827586206896, 0.10324483775811207, 0.10271616652828847, 0.10062893081761008, 0.10020703933747412, 0.099558607160372709, 0.09929078014184399, 0.098484848484848495, 0.09826589595375726, 0.09657039711191337, 0.095785440613026809, 0.095320623916811092, 0.095238095238095247, 0.092783505154639179, 0.092378752886836044, 0.0922266139657444, 0.092105263157894732, 0.091476091476091453, 0.090909090909090925, 0.090410958904109578, 0.090225563909774417, 0.090000000000000011, 0.089724497393894279, 0.089147286821705418, 0.087734241908006855, 0.086767895878524931, 0.086206896551724144, 0.085714285714285687, 0.084620786516853938, 0.081818181818181818, 0.081081081081081058, 0.079136690647482008, 0.078947368421052627, 0.078787878787878782, 0.076252723311546824, 0.07567567567567568, 0.074829931972789115, 0.074576271186440682, 0.074188562596599714, 0.07154213036565979, 0.06968641114982578, 0.066465256797583083, 0.064935064935064943, 0.063953488372093026, 0.060606060606060594, 0.059390862944162438, 0.058823529411764705, 0.057352941176470593, 0.056701030927835065, 0.055900621118012424, 0.054890219560878244, 0.054794520547945209, 0.054650047938638542, 0.052770448548812673, 0.052631578947368418, 0.051321928460342142, 0.05022831050228313, 0.048351648351648353, 0.047957371225577264, 0.046052631578947366, 0.043307086614173221, 0.041284403669724766, 0.038297872340425532, 0.037499999999999999, 0.037288135593220334, 0.035856573705179279, 0.032448377581120937, 0.031161473087818695, 0.028423772609819112, 0.0231578947368421, 0.017023134002618939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print user_list\n",
    "print len(final_list[0])\n",
    "# for i, j, sim in user_sim_list:\n",
    "#     if i,j,sim\n",
    "user_sim_list = final_list[1]\n",
    "#print user_sim_list\n",
    "a = zip(*user_sim_list)[2]\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 6 4 9 8 7] [3 0 2 5]\n",
      "train 1\n",
      "train 6\n",
      "train 4\n",
      "train 9\n",
      "train 8\n",
      "train 7\n",
      "test 3\n",
      "test 0\n",
      "test 2\n",
      "test 5\n",
      "[8 7 1 5 4 9] [3 6 2 0]\n",
      "train 8\n",
      "train 7\n",
      "train 1\n",
      "train 5\n",
      "train 4\n",
      "train 9\n",
      "test 3\n",
      "test 6\n",
      "test 2\n",
      "test 0\n",
      "[5 2 3 4 8 9] [6 7 1 0]\n",
      "train 5\n",
      "train 2\n",
      "train 3\n",
      "train 4\n",
      "train 8\n",
      "train 9\n",
      "test 6\n",
      "test 7\n",
      "test 1\n",
      "test 0\n"
     ]
    }
   ],
   "source": [
    "trainset = [0,1,2,3,4,5,6,7,8,9]\n",
    "ss = cross_validation.ShuffleSplit(len(trainset), n_iter=3, test_size=0.33)\n",
    "for traincv, testcv in ss:\n",
    "        print traincv, testcv\n",
    "        for i in traincv:\n",
    "            print 'train', i\n",
    "        for i in testcv:\n",
    "            print 'test', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/joekaojoekao/PycharmProjects/push/github/dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from /Users/joekaojoekao/PycharmProjects/push/github/dict.txt.big ...\n",
      "Loading model from cache /var/folders/qn/v8s1xx6d7qgclyhkk1t701zc0000gn/T/jieba.u28e5fd167ca6b25e789769ad04c48668.cache\n",
      "DEBUG:jieba:Loading model from cache /var/folders/qn/v8s1xx6d7qgclyhkk1t701zc0000gn/T/jieba.u28e5fd167ca6b25e789769ad04c48668.cache\n",
      "Loading model cost 1.19007706642 seconds.\n",
      "DEBUG:jieba:Loading model cost 1.19007706642 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: 28\n",
      "new: 28\n",
      "with user: 19\n",
      "total word 715\n",
      "stop word 18\n",
      "num_word: 1 \t18\n",
      "after filter: 18\n",
      "0.210526315789\n"
     ]
    }
   ],
   "source": [
    "#########test run\n",
    "\n",
    "## import processed push data\n",
    "with open('/Users/joekaojoekao/PycharmProjects/push/github/visualized/select_pushes101.txt', 'rb') as fin:\n",
    "    s = fin.read().split('\\n')\n",
    "    lines = []\n",
    "    for line in s:\n",
    "        lines.append(line.split('\\t'))\n",
    "    fin.close()\n",
    "\n",
    "## make a dict\n",
    "sample_dict = {}\n",
    "for i in lines:\n",
    "    if len(i) != 2:\n",
    "        continue\n",
    "    uid = i[0]\n",
    "    push = i[1]\n",
    "    if uid not in sample_dict:\n",
    "        sample_dict[uid] = [push]\n",
    "    else:\n",
    "        sample_dict[uid].append(push)\n",
    "\n",
    "## new dict with values containing push & seg_list\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "jieba.analyse.set_stop_words('stopword_pool/merged_stopword.txt')\n",
    "sample_dict_jieba = {}\n",
    "for uid in sample_dict.keys():\n",
    "    pushes = sample_dict[uid]\n",
    "    if len(pushes) > 0:\n",
    "        sample_dict_jieba[uid] = []\n",
    "        for push in pushes:\n",
    "            seg_list = list(jieba.cut(push, cut_all=False))\n",
    "            sample_dict_jieba[uid].append((push,seg_list))\n",
    "\n",
    "\n",
    "\n",
    "## filter pushes by setting gt_numword (meaningful), gt_numpush (active)\n",
    "NUM_WORD_GT = 4\n",
    "NUM_PUSH_GT = 3 #for 6 fold-cv\n",
    "\n",
    "new_pushes = {}\n",
    "for k in sample_dict.keys():\n",
    "    gt_push = [x for x in sample_dict[k] if len(x) > NUM_WORD_GT]\n",
    "    if len(gt_push) > 0:\n",
    "        new_pushes[k] = gt_push\n",
    "\n",
    "user_list = []\n",
    "for k in new_pushes.keys():\n",
    "    if len(new_pushes[k]) >= NUM_PUSH_GT:\n",
    "        user_list.append(k)\n",
    "        \n",
    "print 'origin:', len(sample_dict)\n",
    "print 'new:', len(new_pushes)\n",
    "print 'with user:', len(user_list)\n",
    "\n",
    "\n",
    "## Doing cross validation\n",
    "from sklearn import cross_validation\n",
    "dict_user = {} #training\n",
    "dict_user_ans = {} #testing\n",
    "for uid in user_list:\n",
    "    training_set = sample_dict_jieba[uid]\n",
    "    cv = cross_validation.KFold(len(training_set), n_folds=3, indices=True, shuffle=False, random_state=None, k=None)\n",
    "    \n",
    "    for traincv, testcv in cv:    \n",
    "        dict_user[uid] = []\n",
    "        for i in traincv:\n",
    "            dict_user[uid].append(training_set[i])\n",
    "            \n",
    "        dict_user_ans[uid] = []\n",
    "        for i in testcv:\n",
    "            dict_user_ans[uid].append(training_set[i])\n",
    "            \n",
    "\n",
    "## prepare for trainset and testset(ans)\n",
    "import pttfunc\n",
    "dict_user_count = pttfunc.count_dict(dict_user) #count the freq\n",
    "dict_user_count_ans = pttfunc.count_dict(dict_user_ans) #count the freq for ans(test)\n",
    "\n",
    "## count all using words freq, preparing for generating sorted sw_list \n",
    "count_all = Counter()\n",
    "for v in dict_user_count.values():\n",
    "    count_all += Counter(v)\n",
    "from collections import OrderedDict\n",
    "dict_all_count = OrderedDict(sorted(dict(count_all).items(), key=lambda t: t[1], reverse=True))\n",
    "\n",
    "## set stopword percentage(in global push)\n",
    "W_PERCENT = 0.025\n",
    "word = dict_all_count.keys()\n",
    "stopwords = [x for x in word if dict_all_count[x] >= dict_all_count[word[int(len(word) * W_PERCENT)]]]\n",
    "#rarewords = [x for x in word if dict_all_count[x] <= dict_all_count[word[int(len(word) * (1-W_PERCENT))]]] #0.975\n",
    "\n",
    "## stop word list\n",
    "sw_list = [x for x in stopwords] \n",
    "## rare word list\n",
    "#rw_list = [x for x in rarewords] \n",
    "print 'total word', len(word)\n",
    "print 'stop word', len(sw_list)\n",
    "#print 'rare word', len(rw_list)\n",
    "\n",
    "## select stopword less than 6 word\n",
    "K_NUMWORD = 6\n",
    "sw_count_dict = {}\n",
    "for w in sw_list:\n",
    "    sw_count_dict.setdefault(len(w),[]).append(w)\n",
    "selected_sw = []\n",
    "for k in sw_count_dict.keys()[0:K_NUMWORD]:\n",
    "    print 'num_word:',k,'\\t',len(sw_count_dict[k])\n",
    "    selected_sw += sw_count_dict[k]\n",
    "print 'after filter:', len(selected_sw)\n",
    "\n",
    "\n",
    "## generate training/testing vectors by sw_word freq / total wordfreq\n",
    "general_vec = {}\n",
    "for uid in user_list: # for each user id\n",
    "    user_len = sum([len(x) for x in dict_user_count[uid]]) #total word freq\n",
    "    if user_len > 0:\n",
    "        vec = [dict_user_count[uid].get(w, 0) for w in selected_sw]\n",
    "        g_vec = [float(x) / user_len for x in vec]\n",
    "        general_vec[uid] = g_vec\n",
    "\n",
    "general_vec_ans = {}\n",
    "for uid in user_list: # for each user id\n",
    "    user_len = sum([len(x) for x in dict_user_count_ans[uid]]) #total word freq\n",
    "    #print sum(v.values())\n",
    "    if user_len > 0:\n",
    "        #vec = [jvc_grams_count[idx].get(w, 0) for w in new_sw_list] #stopword without function words\n",
    "\n",
    "        vec = [dict_user_count_ans[uid].get(w, 0) for w in selected_sw]\n",
    "        g_vec = [float(x) / user_len for x in vec]\n",
    "        general_vec_ans[uid] = g_vec\n",
    "\n",
    "##calculate similarity for each user pair\n",
    "\n",
    "import pttfunc\n",
    "import numpy as np\n",
    "sim_list = np.array((0.0, 0.0, 0.0))\n",
    "for i in xrange(len(user_list)):\n",
    "    for j in xrange(len(user_list)):\n",
    "        #wj_sw = pttfunc.weighted_jaccard(general_vec[user_list[i]], general_vec_ans[user_list[j]])\n",
    "        \n",
    "        sim_list = np.vstack((sim_list, np.array((round(float(i),1), round(float(j),1), wj_sw))))\n",
    "\n",
    "#sorting\n",
    "sim_list = sim_list[1:]\n",
    "sim_list = sim_list[sim_list[:,2].argsort()]\n",
    "sim_list = sim_list[::-1]\n",
    "\n",
    "#make final list\n",
    "user_sim_list = []\n",
    "for i, j, sim in sim_list:\n",
    "    user_sim_list.append((user_list[int(i)], user_list[int(j)] + 'ANS', sim))\n",
    "\n",
    "## evaluation\n",
    "a = 0\n",
    "for i,j,sim in user_sim_list:\n",
    "    if i == j[:-3] and sim > 0.3:\n",
    "        a+=1\n",
    "b = len(user_list)\n",
    "print float(a)/ b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0526315789474\n"
     ]
    }
   ],
   "source": [
    "from IPython.html.widgets import interact\n",
    "def evaluate(x):\n",
    "    a = 0\n",
    "    for i,j,sim in user_sim_list:\n",
    "        if i in j and sim >= x:\n",
    "            a+=1\n",
    "    b = len(user_list)\n",
    "    print float(a) / b\n",
    "interact(evaluate, x=(0.0,1.0,0.00001));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7] [0 1 2]\n",
      "[0 1 2 6 7] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7]\n",
      "akaihuang [('\\xe9\\x80\\x99\\xe6\\x9c\\x89\\xe9\\xbb\\x9e\\xe5\\x81\\x87\\xe5\\x90\\xa7\\xef\\xbc\\x8c\\xe7\\x8f\\xbe\\xe5\\x9c\\xa8\\xe6\\x98\\xaf\\xe6\\x89\\x8b\\xe6\\xa9\\x9f\\xe6\\xb2\\x92\\xe9\\x9b\\xbb\\xe4\\xba\\x86\\xe5\\x97\\x8e XD', [u'\\u9019', u'\\u6709\\u9ede', u'\\u5047', u'\\u5427', u'\\uff0c', u'\\u73fe\\u5728', u'\\u662f', u'\\u624b\\u6a5f', u'\\u6c92\\u96fb', u'\\u4e86', u'\\u55ce', u' ', u'XD']), ('\\xe4\\xbd\\xa0\\xe9\\x82\\x8f\\xe8\\xbc\\xaf\\xe6\\x9c\\x89\\xe5\\x95\\x8f\\xe9\\xa1\\x8c...\\xef\\xbc\\x8c\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xb8\\x8d\\xe6\\x89\\xbf\\xe8\\xaa\\x8d\\xe9\\x9b\\x99\\xe9\\x87\\x8d\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe6\\xb2\\x92\\xe9\\x8c\\xaf\\xef\\xbc\\x8c\\xe4\\xb8\\x8d\\xe9\\x81\\x8e...', [u'\\u4f60', u'\\u908f\\u8f2f', u'\\u6709', u'\\u554f\\u984c', u'...', u'\\uff0c', u'\\u5927\\u9678', u'\\u4e0d', u'\\u627f\\u8a8d', u'\\u96d9\\u91cd', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d\\u6c92', u'\\u932f', u'\\uff0c', u'\\u4e0d\\u904e', u'...']), ('\\xe4\\xb8\\xad\\xe8\\x8f\\xaf\\xe6\\xb0\\x91\\xe5\\x9c\\x8b\\xe5\\x9c\\x8b\\xe7\\xb1\\x8d\\xe5\\x9c\\xa8\\xe4\\xbb\\x96\\xe5\\x80\\x91\\xe7\\x9c\\xbc\\xe4\\xb8\\xad\\xe6\\x98\\xaf\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe5\\x97\\x8e \\xe7\\xa7\\x91\\xe7\\xa7\\x91', [u'\\u4e2d\\u83ef\\u6c11\\u570b', u'\\u570b\\u7c4d', u'\\u5728', u'\\u4ed6\\u5011', u'\\u773c\\u4e2d', u'\\u662f', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d', u'\\u55ce', u' ', u'\\u79d1\\u79d1'])]\n",
      "akaihuang [('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86'])]\n"
     ]
    }
   ],
   "source": [
    "for i,j in cv:\n",
    "    print i,j\n",
    "for k,v in dict_user.items():\n",
    "    print k,v\n",
    "    break\n",
    "for k,v in dict_user_ans.items():\n",
    "    print k,v\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##import processed push data\n",
    "\n",
    "#/Users/joekaojoekao/PycharmProjects/push/github/visualized/select_pushes1000_1.txt\n",
    "with open('/Users/joekaojoekao/PycharmProjects/push/github/visualized/select_pushes101.txt', 'rb') as fin:\n",
    "    s = fin.read().split('\\n')\n",
    "    lines = []\n",
    "    for line in s:\n",
    "        lines.append(line.split('\\t'))\n",
    "    fin.close()\n",
    "\n",
    "sample_dict = {}\n",
    "for i in lines:\n",
    "    \n",
    "    #print len(i)\n",
    "    #if len(i) >= 3:\n",
    "    if len(i) != 2:\n",
    "        continue\n",
    "    uid = i[0]\n",
    "    push = i[1]\n",
    "    if uid not in sample_dict:\n",
    "        sample_dict[uid] = [push]\n",
    "    else:\n",
    "        sample_dict[uid].append(push)\n",
    "#print sample_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/joekaojoekao/PycharmProjects/push/github/dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from /Users/joekaojoekao/PycharmProjects/push/github/dict.txt.big ...\n",
      "Dumping model to file cache /var/folders/qn/v8s1xx6d7qgclyhkk1t701zc0000gn/T/jieba.u28e5fd167ca6b25e789769ad04c48668.cache\n",
      "DEBUG:jieba:Dumping model to file cache /var/folders/qn/v8s1xx6d7qgclyhkk1t701zc0000gn/T/jieba.u28e5fd167ca6b25e789769ad04c48668.cache\n",
      "Loading model cost 4.15047812462 seconds.\n",
      "DEBUG:jieba:Loading model cost 4.15047812462 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "##segment pushes\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "jieba.analyse.set_stop_words('stopword_pool/merged_stopword.txt')\n",
    "\n",
    "sample_dict_jieba = {}\n",
    "for uid in sample_dict.keys():\n",
    "    pushes = sample_dict[uid]\n",
    "    if len(pushes) > 0:\n",
    "        sample_dict_jieba[uid] = []\n",
    "        for push in pushes:\n",
    "            seg_list = list(jieba.cut(push, cut_all=False))\n",
    "            sample_dict_jieba[uid].append((push,seg_list))\n",
    "#從ptt push開始處理\n",
    "#我要uid:push&trunked word\n",
    "#幹 要現切 因為產生的東西只剩uid+push(無順序無法查)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\xe9\\x80\\x99\\xe6\\x9c\\x89\\xe9\\xbb\\x9e\\xe5\\x81\\x87\\xe5\\x90\\xa7\\xef\\xbc\\x8c\\xe7\\x8f\\xbe\\xe5\\x9c\\xa8\\xe6\\x98\\xaf\\xe6\\x89\\x8b\\xe6\\xa9\\x9f\\xe6\\xb2\\x92\\xe9\\x9b\\xbb\\xe4\\xba\\x86\\xe5\\x97\\x8e XD', [u'\\u9019', u'\\u6709\\u9ede', u'\\u5047', u'\\u5427', u'\\uff0c', u'\\u73fe\\u5728', u'\\u662f', u'\\u624b\\u6a5f', u'\\u6c92\\u96fb', u'\\u4e86', u'\\u55ce', u' ', u'XD']), ('\\xe4\\xbd\\xa0\\xe9\\x82\\x8f\\xe8\\xbc\\xaf\\xe6\\x9c\\x89\\xe5\\x95\\x8f\\xe9\\xa1\\x8c...\\xef\\xbc\\x8c\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xb8\\x8d\\xe6\\x89\\xbf\\xe8\\xaa\\x8d\\xe9\\x9b\\x99\\xe9\\x87\\x8d\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe6\\xb2\\x92\\xe9\\x8c\\xaf\\xef\\xbc\\x8c\\xe4\\xb8\\x8d\\xe9\\x81\\x8e...', [u'\\u4f60', u'\\u908f\\u8f2f', u'\\u6709', u'\\u554f\\u984c', u'...', u'\\uff0c', u'\\u5927\\u9678', u'\\u4e0d', u'\\u627f\\u8a8d', u'\\u96d9\\u91cd', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d\\u6c92', u'\\u932f', u'\\uff0c', u'\\u4e0d\\u904e', u'...']), ('\\xe4\\xb8\\xad\\xe8\\x8f\\xaf\\xe6\\xb0\\x91\\xe5\\x9c\\x8b\\xe5\\x9c\\x8b\\xe7\\xb1\\x8d\\xe5\\x9c\\xa8\\xe4\\xbb\\x96\\xe5\\x80\\x91\\xe7\\x9c\\xbc\\xe4\\xb8\\xad\\xe6\\x98\\xaf\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe5\\x97\\x8e \\xe7\\xa7\\x91\\xe7\\xa7\\x91', [u'\\u4e2d\\u83ef\\u6c11\\u570b', u'\\u570b\\u7c4d', u'\\u5728', u'\\u4ed6\\u5011', u'\\u773c\\u4e2d', u'\\u662f', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d', u'\\u55ce', u' ', u'\\u79d1\\u79d1']), ('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86'])]\n"
     ]
    }
   ],
   "source": [
    "print sample_dict_jieba.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這有點假吧，現在是手機沒電了嗎 XD\n",
      "你邏輯有問題...，大陸不承認雙重【國】籍沒錯，不過...\n",
      "中華民國國籍在他們眼中是【國】籍嗎 科科\n",
      "大陸人在我方法律本來就不算外國人，這算基本常識了\n"
     ]
    }
   ],
   "source": [
    "for p in sample_dict_jieba.values()[0]:\n",
    "    print p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 分成兩個question ans (cv結束後)再統計? 或是到generate vec的時候統計好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ptt_pushes_freq_byID_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1bc51bcf235b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#WRONG!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mptt_pushes_freq_byID_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ptt_pushes_freq_byID_new' is not defined"
     ]
    }
   ],
   "source": [
    "#print ptt_pushes_freq_byID.values()[0]\n",
    "\n",
    "#WRONG!\n",
    "for k,v in ptt_pushes_freq_byID_new.iteritems():\n",
    "    print k\n",
    "    for kk,vv in v.iteritems():\n",
    "        print kk,vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "19\n",
      "['akaihuang', 'jennywalk', 'C4891', 'morgan168', 'AAAB', 'AAAD', 'fst1985', 'aoiaoi', 'andy80209', 'fhuocrkt', 'wxtab019', 'keithking', 'wilsonno1', 'douglasyeh', 'Meow0129', 'chind', 'motorolla', 'Yakyuboy51', 'feather9298']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "#set gt_numword (meaningful), gt_numpush (active)\n",
    "NUM_WORD_GT = 4\n",
    "NUM_PUSH_GT = 3 #for 6 fold-cv\n",
    "\n",
    "new_pushes = {}\n",
    "for k in sample_dict.keys():\n",
    "    gt_push = [x for x in sample_dict[k] if len(x) > NUM_WORD_GT]\n",
    "    if len(gt_push) > 0:\n",
    "        new_pushes[k] = gt_push\n",
    "\n",
    "user_list = []\n",
    "for k in new_pushes.keys():\n",
    "    if len(new_pushes[k]) >= NUM_PUSH_GT:\n",
    "        user_list.append(k)\n",
    "        \n",
    "print len(sample_dict)\n",
    "print len(new_pushes)\n",
    "print len(user_list)\n",
    "print user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "from sklearn import cross_validation\n",
    "#training_set = nltk.classify.apply_features(extract_features, documents)\n",
    "#dict_user = {} #training\n",
    "#dict_user_ans = {} #testing\n",
    "CV_TIMES = 3\n",
    "\n",
    "#list_user = [{}] * 3\n",
    "#list_user_ans = [{}] * 3\n",
    "\n",
    "list_user = [{} for i in range(3)] \n",
    "list_user_ans = [{} for i in range(3)] \n",
    "\n",
    "\n",
    "for uid in user_list:\n",
    "    training_set = sample_dict_jieba[uid]\n",
    "    #cv = cross_validation.KFold(len(training_set), n_folds=3, indices=True, shuffle=False, random_state=None, k=None)\n",
    "    #trainset = [0,1,2,3,4,5,6,7,8,9]\n",
    "    cv = cross_validation.ShuffleSplit(len(training_set), n_iter=CV_TIMES, test_size=0.33) # 2/3 for train, 1/3 for test, do 3 times  \n",
    "    \n",
    "    #for i in training_set:\n",
    "        #print i[0]\n",
    "    \n",
    "    for n, (traincv, testcv) in enumerate(cv): #每個user都有3組cv的推文\n",
    "        #print n, traincv, testcv\n",
    "        \n",
    "        train_list = [training_set[i] for i in traincv]\n",
    "        test_list = [training_set[i] for i in testcv]\n",
    "        \n",
    "        for i in zip(*train_list)[0]:\n",
    "            print i\n",
    "        print '---'\n",
    "        for i in zip(*test_list)[0]:\n",
    "            print i\n",
    "        \n",
    "        list_user[n][uid] = train_list\n",
    "        list_user_ans[n][uid] = test_list\n",
    "        \n",
    "#         list_user[n][uid] = []\n",
    "#         for i in traincv:\n",
    "#             list_user[n][uid].append(training_set[i]) #list_user[第n次cv][user uid]\n",
    "        \n",
    "#         list_user_ans[n][uid] = []\n",
    "#         for i in testcv:\n",
    "#             list_user_ans[n][uid].append(training_set[i])\n",
    "        \n",
    "        #print uid\n",
    "        #for v in list_user[0][uid]:\n",
    "            #print v[0]\n",
    "            #for vv in v:\n",
    "                #print vv[0]\n",
    "\n",
    "\n",
    "# for p in list_user[0].values()[1]:\n",
    "#     for pp in p:\n",
    "#         print p[0]\n",
    "# print '-----------'\n",
    "# for p in list_user[1].values()[1]:\n",
    "#     for pp in p:\n",
    "#         print p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akaihuang\n",
      "中華民國國籍在他們眼中是【國】籍嗎 科科\n",
      "大陸人在我方法律本來就不算外國人，這算基本常識了\n",
      "feather9298\n",
      "預算再追加五百億\n",
      "我今天睡過頭只能領便當\n",
      "推我應該有五百內吧\n",
      "果然壓力大XDDD\n",
      "可望=不可能\n",
      "jennywalk\n",
      "全家，作超商可要搶破頭呢！\n",
      "私底下也能解決，把阿桑罵罵就好，現除了道歉火人外沒法\n",
      "昨晚就有建議原po了，丟上網路語論下，會較嚴重。\n",
      "這樣變鬧版-.-？\n",
      "了，我個人是認為罵罵，東西當下拿回來就好。\n",
      "沒跟到，不過請問一下反對的理由是什麼？新計程還遠通？\n",
      "wilsonno1\n",
      "中立 跟中天大概是差不多的意思\n",
      "姚立明真的好強orz\n",
      "chind\n",
      "哦? 鶴拳的影片 能附上網址嗎? 此鶴拳跟洪門拳的鶴拳不一樣\n",
      "能免則免 你頂多把對方打倒 對方卻很有可能把你砍死\n",
      "真正危險的地方是在 被動攻擊的狀態 不排除有偷襲的可能\n",
      "網頁版的藍色比較亮 可以參考 這藍色在BBS是最亮了\n",
      "C4891\n",
      "明明就是綠黨在背後煽動的！又是藍綠惡鬥！逢中必反！！！\n",
      "翻了一大堆稅金買的警車誰要賠啊 初估至少損失一億人民幣！\n",
      "原po是台灣人吧 香港人是指那照片的拍攝者\n",
      "沒禮貌的暴民、恐怖份子！\n",
      "某樓的不要造謠 哪有死人啊 明明只有「拍拍肩膀」！！！\n",
      "以前台灣人抗爭也滿強捍的....\n",
      "douglasyeh\n",
      "014之亂要亂個014年\n",
      "35秒13k比較有可能\n",
      "罵得很好啊\n",
      "一樓也危險了...\n",
      "morgan168\n",
      "來來來來來來來來來來來來來來來來來來來來來來來來\n",
      "大家辛苦了! 真的很感動! 希望真相早日水落石出!\n",
      "wxtab019\n",
      "記得備份讓他等著上法院了\n",
      "這個有說 好像那時候學校公告還沒有貼報名連結\n",
      "還是自己找出來然後再FB傳的\n",
      "如果被告就說新聞說這樣都可以 而且還無罪了\n",
      "反正還會噴水消暑\n",
      "到中華電信回報好了...\n",
      "自以為這種活動很好玩?P幣有用? 之後大家都換用人民幣了\n",
      "哪來的山豬...我都沒看過\n",
      "我走了 ~~我又回來了~~~我又走了 ~~~我又回來了~~~\n",
      "不是柔性勸離 拍拍肩膀而已嗎?一定是哪裡搞錯了\n",
      "去掛急診不要看門診阿\n",
      "反正多弄幾個坑出來坦 全部弄在一起就有些可以趁亂摸過\n",
      "有人送保險套 有人送素肚 剛剛好阿\n",
      "這不是看條文內容就知道了?\n",
      "mod好像沒有可以回報讓他下架的地方?\n",
      "某版昨天一堆高潮的現在又對這個消息當作完全沒看到了\n",
      "以後走在大馬路上的人 如果被性騷擾也都自己活該\n",
      "還不就紫爆活動造成八卦版混亂\n",
      "剛出生...\n",
      "不只紫了吧....水泡都腫的要比腳大了...\n",
      "系統自動刪文了吧\n",
      "停工就等於工人放假而已\n",
      "反正上級都已經說這次學運出事最多就申誡兩隻 爆出來沒怕\n",
      "keithking\n",
      "真可憐 認直做事也要被冠上顏色 板主我支持你啦~\n",
      "SAH是急性出血性中風中的一類…\n",
      "說白話點就是：腦出血\n",
      "條杯杯：我們在抓闖紅燈的 沒空管立委兒子啦\n",
      "李主管是吧？\n",
      "人笨：你就讓他打嘛，他打到爽就不打了。\n",
      "這是一個沒有耐心看第二次的懶人包 XDDD 原po GJ!\n",
      "AAAB\n",
      "[徵求] 台北、明天白天會待在店面的人、想借用貴店的插座\n",
      "拜託請幫這個忙, 或是幫忙問問熟識的店家, 請站內信給我,謝謝\n",
      "Meow0129\n",
      "中小企業主很多都自己兼員工幹上來的 會寫PHP很奇怪?\n",
      "中小企業主很多都自己兼員工幹上來的 會寫PHP很奇怪?\n",
      "中小企業主很多都自己兼員工幹上來的 會寫PHP很奇怪?\n",
      "AAAD\n",
      "\"海洋動物住的游泳池的管理員\"是誰\n",
      "馬政府無能→阿扁下台負責\n",
      "fst1985\n",
      "XDDDDDDDDDDDDDDDDDDDD\n",
      "推DASH\n",
      "aoiaoi\n",
      "沒看到2006還以為他造反了 XD\n",
      "感謝KMT 不然學生 其實不太有理由繼續龜立院\n",
      "大快人心 XDD\n",
      "其實我覺得還好 但人都死了也不想酸 =.=\n",
      "我被罵沒腦 我要告尼 Q_Q\n",
      "第一篇可以 後面自刪都算鬧版 感覺還蠻詭異的...\n",
      "便衣拍人 算行使職權嗎? 為什麼一定要出示證件阿 ?\n",
      "弱弱的問一下 為什麼便衣拍人違法 民眾卻可以拍他蒐證?\n",
      "K少回公告 被桶 沒啥爭議吧..\n",
      "andy80209\n",
      "1315發車，地點報名表有說\n",
      "他轉文的又不是律師.........\n",
      "衝行政院魏還在車上，奪權?\n",
      "朝聖~PTT要被關了\n",
      "你說陳林有一腿，信的人都比魏奪權還多上百倍\n",
      "辦案交給警察，查IP就交給迷你158\n",
      "住附近的有車就直接送去吧 不過注意安全\n",
      "要信他我不如信神豬\n",
      "BS我有印象\n",
      "台北市那個 他標題騙人\n",
      "最後一個嚴格來說沒錯\n",
      "XDDDDDDDDDDD\n",
      "第一次看到版主戰？那你應該很少去NBA\n",
      "你乾脆說金小刀在飛機上遙控政府......幹，這真的有可能\n",
      "Yakyuboy51\n",
      "那個路口平常已經夠塞了 還這樣製造混亂\n",
      "影片這麼明顯還缺少證據？那什麼才叫做證據？\n",
      "fhuocrkt\n",
      "肥螳螂辛酸史\n",
      "我願意當日本人!\n",
      "可惜伊眉被炒了 不然三立的顏色應該很想發這篇\n",
      "李正男是天下父母心的\n",
      "誰呀亂水桶\n",
      "沒錯吧8神\n",
      "你誰呀有吻過我嗎\n",
      "有黨鄭 有悔意 這個樓下要怎判\n",
      "要我也可以這樣玩 想留誰 晚點S 反正決定權在你嘛\n",
      "只知道明天東海岸的消波塊可能會多了幾塊\n",
      "噓你 我不信找不到 而且你有每個人都問要不要留任嗎?\n",
      "如果真的是事實 怎麼會七天後才得知? 可信度多少?\n",
      "馬大概要使出切割術了\n",
      "你有聞過我嗎\n",
      "袒護就算了 還任由對方刪請辭文 哪招?\n",
      "議員都調查出來了 媒體就算不敢報 議員也能出面阿\n",
      "松花江在哪\n",
      "分身被捅了= =\n",
      "你誰呀 左上角沒有你啊\n",
      "有點菜 應該還沒有梯數\n",
      "台北巿 明天照常辦公、照常上課 這還好吧XD\n",
      "沒P幣拿了\n",
      "海鳥請辭 K少請辭 你有挽留?\n",
      "推 YU0121:...\n",
      "永久水桶比列退好 至少別的板還可以玩\n",
      "[新聞] 父母沒探視 鄭捷沒錢買內褲\n",
      "封鎖媒體 下一個批踢踢\n",
      "= = 下午問過YU0121 他說最近也要請辭了\n",
      "說穿了只是在為你的袒護找一大堆理由罷了 是疏失? 可笑\n",
      "欸檢舉王 你標題要一致喔 有時候標題會打被統ID有時候卻\n",
      "motorolla\n",
      "幹 剛出生舊病危...真的無法接受阿\n",
      "最好是有效力啦..有效力的話籃球架早不知道吃幾回了\n",
      "我鬍朝宗 =馬英九\n"
     ]
    }
   ],
   "source": [
    "for k, v in list_user[0].iteritems():\n",
    "    print k\n",
    "    for vv in v:\n",
    "        print vv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akaihuang\n",
      "你邏輯有問題...，大陸不承認雙重【國】籍沒錯，不過...\n",
      "這有點假吧，現在是手機沒電了嗎 XD\n",
      "feather9298\n",
      "不說謊才是新聞\n",
      "高調!!!!!\n",
      "wooooow\n",
      "jennywalk\n",
      "2000美給一個外國人喇舌台灣女，該關心的不關心\n",
      "這種待遇在高雄屏東真的差不多阿。\n",
      "記者加油！！\n",
      "樓上有人說不如作超商？我屏東老家，全村也才二小七一\n",
      "wilsonno1\n",
      "那請趕快叫中國去宣布新加坡是中國不可分割的一部分\n",
      "chind\n",
      "除非平常很有sense 不讓別人靠近一公尺以內\n",
      "避免晚上獨自一個人走暗巷 少跟人結仇 財不露白 這些較重要\n",
      "我猜對了 果然是高老師\n",
      "C4891\n",
      "大家等著看這群暴民散場後地上垃圾有沒有撿乾淨！！！\n",
      "韓國人平常也滿奴的啊 只是抗爭的時候才會強捍\n",
      "-----------------鄉民要團結，團結真有力-----------------\n",
      "douglasyeh\n",
      "肯德基分店這麼少 結果光大里就開2家\n",
      "超級菜市場名耶哈哈\n",
      "5566還是去NBA板反串吧\n",
      "morgan168\n",
      "硍! 晚上要作惡夢惹~\n",
      "看來高雄(譚)市需要蝙蝠俠!!\n",
      "wxtab019\n",
      "有些站好像過路的 可以不用買票進去\n",
      "警察和政府官員不是都說警察沒打人?\n",
      "還好我家沒裝第四台 不用看這種節目...\n",
      "我走在你身邊會忍不住 這樣是不是也不會被告?改天去試試\n",
      "所以如果他在自己女兒旁邊 他也睡不下去嗎?\n",
      "應該可以去NCC檢舉了...只是不知道會不會被吃掉就是...\n",
      "不過也是4/13 就有人發現 然後中正就已經有在FB上傳了\n",
      "自己做錯事還要別人求你向他道歉? 要不要跪下來求你?\n",
      "先想想造成抗爭的原因是什麼吧 如果大家都過得很好\n",
      "停工一下 工人回去剛好特休修一修 過幾天繼續開工啦\n",
      "公共場所就大家都可以評論?走在路上不是也可以說小姐好辣\n",
      "有人會無聊沒事跑去抗爭嗎\n",
      "keithking\n",
      "我猜明天就是立委帶兒子出來，然後兒子哭哭道歉崩潰這樣\n",
      "=============以下開放記者入場，GO!==================\n",
      "幫高調 打到SAH是怎樣… 往死裡打？\n",
      "記者快來抄\n",
      "AAAB\n",
      "文章有po在wanted但可能是很難徵求, 沒有人回應...\n",
      "插座是為了想用麥克風呼籲過路民眾晚上6點參加凱道的活動\n",
      "Meow0129\n",
      "中小企業主很多都自己兼員工幹上來的 會寫PHP很奇怪?\n",
      "中小企業主很多都自己兼員工幹上來的 會寫PHP很奇怪?\n",
      "AAAD\n",
      "用手槍=遏止力不足 ????\n",
      "fst1985\n",
      "XDDDD\n",
      "我要成為海賊王!!!!\n",
      "aoiaoi\n",
      "你先去看懶人包 再來發廢文好不好\n",
      "無聊的活動\n",
      "看了下一篇 關鍵小隊長說他在\"執勤中\" 那確實成立\n",
      "故意雙關的 反正凹大樹就好了\n",
      "感覺 案情不單純耶...\n",
      "andy80209\n",
      "單單肉搜那沒啥，但他有濫用職權的疑慮，他是鴿子\n",
      "差點被告的前版主撐多久阿?\n",
      "你去上訴阿，法官就事實認定沒他的事\n",
      "他出來整頓秩序出來坦，現再有人說他奪權XDDD\n",
      "他衝政院還無保請回，換我要告法官瀆職了\n",
      "總統府這次要多少警力阿...不過30台不好生出來吧\n",
      "某Q想戰 科科\n",
      "Yakyuboy51\n",
      "R.I.P. 沒有經過那邊~但希望早日釐清~\n",
      "爛透了...................................\n",
      "fhuocrkt\n",
      "你誰呀亂么吉\n",
      "轉來拉票 XD\n",
      "路男我的神\n",
      "一直刪文不煩膩\n",
      "我還以為beef被M了= =\n",
      "下抬 叭叭\n",
      "如果真的是 那3800W應該賠得起啦 省了我們的納稅錢了^^\n",
      "原po準備收小禮物了\n",
      "標哥辛苦還沒吃飯阿\n",
      "馬狗沒有錯呀 沒指名道姓\n",
      "恩 想也知道誰會選上\n",
      "我覺得批踢踢快被封鎖了的感覺...\n",
      "竟然是鹿男轉來的\n",
      "我印象中是三個月耶 不用在加兩週\n",
      "你不用期末考喔\n",
      "motorolla\n",
      "反正船公司為了省5萬停泊費~就冒死空船開出去..真是不齒\n",
      "千萬不要少版主阿~我最討厭廢文了~少版主誰刪阿\n"
     ]
    }
   ],
   "source": [
    "for k, v in list_user_ans[0].iteritems():\n",
    "    print k\n",
    "    for vv in v:\n",
    "        print vv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-f7c7e136e828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'akaihuang'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'幹你嗎的真的假的'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlist_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'akaihuang'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "list_user[0].update = dict('幹你嗎的真的假的')\n",
    "print list_user[0]['akaihuang'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'akaihuang': [('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe4\\xbd\\xa0\\xe9\\x82\\x8f\\xe8\\xbc\\xaf\\xe6\\x9c\\x89\\xe5\\x95\\x8f\\xe9\\xa1\\x8c...\\xef\\xbc\\x8c\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xb8\\x8d\\xe6\\x89\\xbf\\xe8\\xaa\\x8d\\xe9\\x9b\\x99\\xe9\\x87\\x8d\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe6\\xb2\\x92\\xe9\\x8c\\xaf\\xef\\xbc\\x8c\\xe4\\xb8\\x8d\\xe9\\x81\\x8e...', [u'\\u4f60', u'\\u908f\\u8f2f', u'\\u6709', u'\\u554f\\u984c', u'...', u'\\uff0c', u'\\u5927\\u9678', u'\\u4e0d', u'\\u627f\\u8a8d', u'\\u96d9\\u91cd', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d\\u6c92', u'\\u932f', u'\\uff0c', u'\\u4e0d\\u904e', u'...']), ('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe9\\x80\\x99\\xe6\\x9c\\x89\\xe9\\xbb\\x9e\\xe5\\x81\\x87\\xe5\\x90\\xa7\\xef\\xbc\\x8c\\xe7\\x8f\\xbe\\xe5\\x9c\\xa8\\xe6\\x98\\xaf\\xe6\\x89\\x8b\\xe6\\xa9\\x9f\\xe6\\xb2\\x92\\xe9\\x9b\\xbb\\xe4\\xba\\x86\\xe5\\x97\\x8e XD', [u'\\u9019', u'\\u6709\\u9ede', u'\\u5047', u'\\u5427', u'\\uff0c', u'\\u73fe\\u5728', u'\\u662f', u'\\u624b\\u6a5f', u'\\u6c92\\u96fb', u'\\u4e86', u'\\u55ce', u' ', u'XD']), ('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe4\\xb8\\xad\\xe8\\x8f\\xaf\\xe6\\xb0\\x91\\xe5\\x9c\\x8b\\xe5\\x9c\\x8b\\xe7\\xb1\\x8d\\xe5\\x9c\\xa8\\xe4\\xbb\\x96\\xe5\\x80\\x91\\xe7\\x9c\\xbc\\xe4\\xb8\\xad\\xe6\\x98\\xaf\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe5\\x97\\x8e \\xe7\\xa7\\x91\\xe7\\xa7\\x91', [u'\\u4e2d\\u83ef\\u6c11\\u570b', u'\\u570b\\u7c4d', u'\\u5728', u'\\u4ed6\\u5011', u'\\u773c\\u4e2d', u'\\u662f', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d', u'\\u55ce', u' ', u'\\u79d1\\u79d1'])]}\n",
      "{'akaihuang': [('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe4\\xbd\\xa0\\xe9\\x82\\x8f\\xe8\\xbc\\xaf\\xe6\\x9c\\x89\\xe5\\x95\\x8f\\xe9\\xa1\\x8c...\\xef\\xbc\\x8c\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xb8\\x8d\\xe6\\x89\\xbf\\xe8\\xaa\\x8d\\xe9\\x9b\\x99\\xe9\\x87\\x8d\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe6\\xb2\\x92\\xe9\\x8c\\xaf\\xef\\xbc\\x8c\\xe4\\xb8\\x8d\\xe9\\x81\\x8e...', [u'\\u4f60', u'\\u908f\\u8f2f', u'\\u6709', u'\\u554f\\u984c', u'...', u'\\uff0c', u'\\u5927\\u9678', u'\\u4e0d', u'\\u627f\\u8a8d', u'\\u96d9\\u91cd', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d\\u6c92', u'\\u932f', u'\\uff0c', u'\\u4e0d\\u904e', u'...']), ('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe9\\x80\\x99\\xe6\\x9c\\x89\\xe9\\xbb\\x9e\\xe5\\x81\\x87\\xe5\\x90\\xa7\\xef\\xbc\\x8c\\xe7\\x8f\\xbe\\xe5\\x9c\\xa8\\xe6\\x98\\xaf\\xe6\\x89\\x8b\\xe6\\xa9\\x9f\\xe6\\xb2\\x92\\xe9\\x9b\\xbb\\xe4\\xba\\x86\\xe5\\x97\\x8e XD', [u'\\u9019', u'\\u6709\\u9ede', u'\\u5047', u'\\u5427', u'\\uff0c', u'\\u73fe\\u5728', u'\\u662f', u'\\u624b\\u6a5f', u'\\u6c92\\u96fb', u'\\u4e86', u'\\u55ce', u' ', u'XD']), ('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe4\\xb8\\xad\\xe8\\x8f\\xaf\\xe6\\xb0\\x91\\xe5\\x9c\\x8b\\xe5\\x9c\\x8b\\xe7\\xb1\\x8d\\xe5\\x9c\\xa8\\xe4\\xbb\\x96\\xe5\\x80\\x91\\xe7\\x9c\\xbc\\xe4\\xb8\\xad\\xe6\\x98\\xaf\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe5\\x97\\x8e \\xe7\\xa7\\x91\\xe7\\xa7\\x91', [u'\\u4e2d\\u83ef\\u6c11\\u570b', u'\\u570b\\u7c4d', u'\\u5728', u'\\u4ed6\\u5011', u'\\u773c\\u4e2d', u'\\u662f', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d', u'\\u55ce', u' ', u'\\u79d1\\u79d1'])]}\n",
      "{'akaihuang': [('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe4\\xbd\\xa0\\xe9\\x82\\x8f\\xe8\\xbc\\xaf\\xe6\\x9c\\x89\\xe5\\x95\\x8f\\xe9\\xa1\\x8c...\\xef\\xbc\\x8c\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xb8\\x8d\\xe6\\x89\\xbf\\xe8\\xaa\\x8d\\xe9\\x9b\\x99\\xe9\\x87\\x8d\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe6\\xb2\\x92\\xe9\\x8c\\xaf\\xef\\xbc\\x8c\\xe4\\xb8\\x8d\\xe9\\x81\\x8e...', [u'\\u4f60', u'\\u908f\\u8f2f', u'\\u6709', u'\\u554f\\u984c', u'...', u'\\uff0c', u'\\u5927\\u9678', u'\\u4e0d', u'\\u627f\\u8a8d', u'\\u96d9\\u91cd', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d\\u6c92', u'\\u932f', u'\\uff0c', u'\\u4e0d\\u904e', u'...']), ('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe9\\x80\\x99\\xe6\\x9c\\x89\\xe9\\xbb\\x9e\\xe5\\x81\\x87\\xe5\\x90\\xa7\\xef\\xbc\\x8c\\xe7\\x8f\\xbe\\xe5\\x9c\\xa8\\xe6\\x98\\xaf\\xe6\\x89\\x8b\\xe6\\xa9\\x9f\\xe6\\xb2\\x92\\xe9\\x9b\\xbb\\xe4\\xba\\x86\\xe5\\x97\\x8e XD', [u'\\u9019', u'\\u6709\\u9ede', u'\\u5047', u'\\u5427', u'\\uff0c', u'\\u73fe\\u5728', u'\\u662f', u'\\u624b\\u6a5f', u'\\u6c92\\u96fb', u'\\u4e86', u'\\u55ce', u' ', u'XD']), ('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86']), ('\\xe4\\xb8\\xad\\xe8\\x8f\\xaf\\xe6\\xb0\\x91\\xe5\\x9c\\x8b\\xe5\\x9c\\x8b\\xe7\\xb1\\x8d\\xe5\\x9c\\xa8\\xe4\\xbb\\x96\\xe5\\x80\\x91\\xe7\\x9c\\xbc\\xe4\\xb8\\xad\\xe6\\x98\\xaf\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe5\\x97\\x8e \\xe7\\xa7\\x91\\xe7\\xa7\\x91', [u'\\u4e2d\\u83ef\\u6c11\\u570b', u'\\u570b\\u7c4d', u'\\u5728', u'\\u4ed6\\u5011', u'\\u773c\\u4e2d', u'\\u662f', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d', u'\\u55ce', u' ', u'\\u79d1\\u79d1'])]}\n"
     ]
    }
   ],
   "source": [
    "for l in list_user:\n",
    "    print l\n",
    "#a = list_user[1]['akaihuang']\n",
    "#for p in a:\n",
    "#    print p[0]\n",
    "\n",
    "# print len(dict_user.values()[0])\n",
    "# print len(dict_user.values()[1])\n",
    "# print len(dict_user.values())\n",
    "# a = dict_user.values()[1]\n",
    "\n",
    "# for push in a[0]:\n",
    "#     print push[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# real do cv \n",
    "final_list = []\n",
    "\n",
    "for i in xrange(CV_TIMES):\n",
    "    dict_user = list_user[i]\n",
    "    dict_user_count = pttfunc.count_dict(dict_user) #count the freq\n",
    "    \n",
    "    dict_user_ans = list_user_ans[i]\n",
    "    dict_user_count_ans = pttfunc.count_dict(dict_user_ans) #count the freq for ans(test)\n",
    "    from collections import Counter\n",
    "    count_all = Counter()\n",
    "    for v in dict_user_count.values():\n",
    "        count_all += Counter(v)\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    dict_all_count = OrderedDict(sorted(dict(count_all).items(), key=lambda t: t[1], reverse=True))\n",
    "\n",
    "    ##gen sw\n",
    "    word = dict_all_count.keys()\n",
    "    W_PERCENT = 0.025 #0.025\n",
    "    ## setting for stopword & rareword percentage\n",
    "    stopwords = [x for x in word if dict_all_count[x] >= dict_all_count[word[int(len(word) * W_PERCENT)]]]\n",
    "    rarewords = [x for x in word if dict_all_count[x] <= dict_all_count[word[int(len(word) * (1-W_PERCENT))]]] #0.975\n",
    "\n",
    "    ## stop word list\n",
    "    sw_list = [x for x in stopwords] \n",
    "    ## rare word list\n",
    "    rw_list = [x for x in rarewords] \n",
    "    print 'total word', len(word)\n",
    "    print 'stop word', len(sw_list)\n",
    "    print 'rare word', len(rw_list)\n",
    "\n",
    "\n",
    "    sw_count_dict = {}\n",
    "    for w in sw_list:\n",
    "        sw_count_dict.setdefault(len(w),[]).append(w)\n",
    "\n",
    "\n",
    "    K_NUMWORD = 6\n",
    "    selected_sw = []\n",
    "    for k in sw_count_dict.keys()[0:K_NUMWORD]:\n",
    "        print 'num_word:',k,'\\t',len(sw_count_dict[k])\n",
    "        selected_sw += sw_count_dict[k]\n",
    "    print len(selected_sw)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##gen vec\n",
    "    import itertools\n",
    "    general_vec = {}\n",
    "    for uid in user_list: # for each user id\n",
    "        user_len = sum([len(x) for x in dict_user_count[uid]]) #total word freq\n",
    "        #print sum(v.values())\n",
    "        if user_len > 0:\n",
    "            #vec = [jvc_grams_count[idx].get(w, 0) for w in new_sw_list] #stopword without function words\n",
    "\n",
    "            vec = [dict_user_count[uid].get(w, 0) for w in selected_sw]\n",
    "            g_vec = [float(x) / user_len for x in vec]\n",
    "            general_vec[uid] = g_vec\n",
    "\n",
    "\n",
    "    general_vec_ans = {}\n",
    "    for uid in user_list: # for each user id\n",
    "        user_len = sum([len(x) for x in dict_user_count_ans[uid]]) #total word freq\n",
    "        #print sum(v.values())\n",
    "        if user_len > 0:\n",
    "            #vec = [jvc_grams_count[idx].get(w, 0) for w in new_sw_list] #stopword without function words\n",
    "\n",
    "            vec = [dict_user_count_ans[uid].get(w, 0) for w in selected_sw]\n",
    "            g_vec = [float(x) / user_len for x in vec]\n",
    "            general_vec_ans[uid] = g_vec\n",
    "\n",
    "    print len(general_vec[user_list[0]])\n",
    "    print len(general_vec_ans[user_list[0]])\n",
    "    \n",
    "    import pttfunc\n",
    "    #comb = gb.getCombination(len(user_list))\n",
    "\n",
    "    ##calculate similarity for each user pair\n",
    "\n",
    "    sim_list = np.array((0.0, 0.0, 0.0))\n",
    "\n",
    "    # for i, j in comb:\n",
    "    #     wj_sw = pttfunc.weighted_jaccard(general_vec[user_list[i]], general_vec_ans[user_list[j]])\n",
    "    #     #sim_list = np.append(sim_list, np.array((k1, k2, wj_sw), dtype=mtype))\n",
    "    #     sim_list = np.vstack((sim_list, np.array((round(float(i),1), round(float(j),1), wj_sw))))\n",
    "\n",
    "    for i in xrange(len(user_list)):\n",
    "        for j in xrange(len(user_list)):\n",
    "            wj_sw = pttfunc.weighted_jaccard(general_vec[user_list[i]], general_vec_ans[user_list[j]])\n",
    "            sim_list = np.vstack((sim_list, np.array((round(float(i),1), round(float(j),1), wj_sw))))\n",
    "\n",
    "\n",
    "\n",
    "    sim_list = sim_list[1:]\n",
    "    sim_list = sim_list[sim_list[:,2].argsort()]\n",
    "    sim_list = sim_list[::-1]\n",
    "\n",
    "\n",
    "\n",
    "    user_sim_list = []\n",
    "    for i, j, sim in sim_list:\n",
    "        user_sim_list.append((user_list[int(i)], user_list[int(j)] + 'ANS', sim))\n",
    "    \n",
    "    final_list.append(user_sim_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.368421052632\n"
     ]
    }
   ],
   "source": [
    "from IPython.html.widgets import interact\n",
    "def evaluate(x, y):\n",
    "    a = 0\n",
    "    user_sim_list = final_list[y]\n",
    "    for i,j,sim in user_sim_list:\n",
    "        if i in j and sim >= x:\n",
    "            a+=1\n",
    "    b = len(user_list)\n",
    "    print float(a) / b\n",
    "\n",
    "\n",
    "interact(evaluate, x=(0.0,1.0,0.01), y=(0, CV_TIMES-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.html.widgets import *\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "def pltsin(f, a):\n",
    "    print f*a\n",
    "interact(pltsin, f=(1,10,0.1), a=(1,10,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\xe4\\xbd\\xa0\\xe9\\x82\\x8f\\xe8\\xbc\\xaf\\xe6\\x9c\\x89\\xe5\\x95\\x8f\\xe9\\xa1\\x8c...\\xef\\xbc\\x8c\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xb8\\x8d\\xe6\\x89\\xbf\\xe8\\xaa\\x8d\\xe9\\x9b\\x99\\xe9\\x87\\x8d\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe6\\xb2\\x92\\xe9\\x8c\\xaf\\xef\\xbc\\x8c\\xe4\\xb8\\x8d\\xe9\\x81\\x8e...', [u'\\u4f60', u'\\u908f\\u8f2f', u'\\u6709', u'\\u554f\\u984c', u'...', u'\\uff0c', u'\\u5927\\u9678', u'\\u4e0d', u'\\u627f\\u8a8d', u'\\u96d9\\u91cd', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d\\u6c92', u'\\u932f', u'\\uff0c', u'\\u4e0d\\u904e', u'...']), ('\\xe9\\x80\\x99\\xe6\\x9c\\x89\\xe9\\xbb\\x9e\\xe5\\x81\\x87\\xe5\\x90\\xa7\\xef\\xbc\\x8c\\xe7\\x8f\\xbe\\xe5\\x9c\\xa8\\xe6\\x98\\xaf\\xe6\\x89\\x8b\\xe6\\xa9\\x9f\\xe6\\xb2\\x92\\xe9\\x9b\\xbb\\xe4\\xba\\x86\\xe5\\x97\\x8e XD', [u'\\u9019', u'\\u6709\\u9ede', u'\\u5047', u'\\u5427', u'\\uff0c', u'\\u73fe\\u5728', u'\\u662f', u'\\u624b\\u6a5f', u'\\u6c92\\u96fb', u'\\u4e86', u'\\u55ce', u' ', u'XD'])]\n",
      "[('\\xe4\\xbd\\xa0\\xe9\\x82\\x8f\\xe8\\xbc\\xaf\\xe6\\x9c\\x89\\xe5\\x95\\x8f\\xe9\\xa1\\x8c...\\xef\\xbc\\x8c\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xb8\\x8d\\xe6\\x89\\xbf\\xe8\\xaa\\x8d\\xe9\\x9b\\x99\\xe9\\x87\\x8d\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe6\\xb2\\x92\\xe9\\x8c\\xaf\\xef\\xbc\\x8c\\xe4\\xb8\\x8d\\xe9\\x81\\x8e...', [u'\\u4f60', u'\\u908f\\u8f2f', u'\\u6709', u'\\u554f\\u984c', u'...', u'\\uff0c', u'\\u5927\\u9678', u'\\u4e0d', u'\\u627f\\u8a8d', u'\\u96d9\\u91cd', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d\\u6c92', u'\\u932f', u'\\uff0c', u'\\u4e0d\\u904e', u'...']), ('\\xe5\\xa4\\xa7\\xe9\\x99\\xb8\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x96\\xb9\\xe6\\xb3\\x95\\xe5\\xbe\\x8b\\xe6\\x9c\\xac\\xe4\\xbe\\x86\\xe5\\xb0\\xb1\\xe4\\xb8\\x8d\\xe7\\xae\\x97\\xe5\\xa4\\x96\\xe5\\x9c\\x8b\\xe4\\xba\\xba\\xef\\xbc\\x8c\\xe9\\x80\\x99\\xe7\\xae\\x97\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe5\\xb8\\xb8\\xe8\\xad\\x98\\xe4\\xba\\x86', [u'\\u5927\\u9678', u'\\u4eba', u'\\u5728', u'\\u6211\\u65b9', u'\\u6cd5\\u5f8b', u'\\u672c\\u4f86', u'\\u5c31', u'\\u4e0d\\u7b97', u'\\u5916\\u570b\\u4eba', u'\\uff0c', u'\\u9019\\u7b97', u'\\u57fa\\u672c\\u5e38\\u8b58', u'\\u4e86'])]\n",
      "[('\\xe4\\xb8\\xad\\xe8\\x8f\\xaf\\xe6\\xb0\\x91\\xe5\\x9c\\x8b\\xe5\\x9c\\x8b\\xe7\\xb1\\x8d\\xe5\\x9c\\xa8\\xe4\\xbb\\x96\\xe5\\x80\\x91\\xe7\\x9c\\xbc\\xe4\\xb8\\xad\\xe6\\x98\\xaf\\xe3\\x80\\x90\\xe5\\x9c\\x8b\\xe3\\x80\\x91\\xe7\\xb1\\x8d\\xe5\\x97\\x8e \\xe7\\xa7\\x91\\xe7\\xa7\\x91', [u'\\u4e2d\\u83ef\\u6c11\\u570b', u'\\u570b\\u7c4d', u'\\u5728', u'\\u4ed6\\u5011', u'\\u773c\\u4e2d', u'\\u662f', u'\\u3010', u'\\u570b', u'\\u3011', u'\\u7c4d', u'\\u55ce', u' ', u'\\u79d1\\u79d1']), ('\\xe9\\x80\\x99\\xe6\\x9c\\x89\\xe9\\xbb\\x9e\\xe5\\x81\\x87\\xe5\\x90\\xa7\\xef\\xbc\\x8c\\xe7\\x8f\\xbe\\xe5\\x9c\\xa8\\xe6\\x98\\xaf\\xe6\\x89\\x8b\\xe6\\xa9\\x9f\\xe6\\xb2\\x92\\xe9\\x9b\\xbb\\xe4\\xba\\x86\\xe5\\x97\\x8e XD', [u'\\u9019', u'\\u6709\\u9ede', u'\\u5047', u'\\u5427', u'\\uff0c', u'\\u73fe\\u5728', u'\\u662f', u'\\u624b\\u6a5f', u'\\u6c92\\u96fb', u'\\u4e86', u'\\u55ce', u' ', u'XD'])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1b2eef1e0313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_user\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdict_user_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpttfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_user\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#count the freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdict_user_count_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpttfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_user_ans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#count the freq for ans(test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joekaojoekao/PycharmProjects/push/github/pttfunc.py\u001b[0m in \u001b[0;36mcount_dict\u001b[0;34m(sample_dict_jieba)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpush_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpush_gram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpush_gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joekaojoekao/anaconda/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    451\u001b[0m         '''\n\u001b[1;32m    452\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joekaojoekao/anaconda/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mself_get\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import pttfunc\n",
    "#print dict_user.values()[0]\n",
    "for v in dict_user.values()[0]:\n",
    "    print v\n",
    "dict_user_count = pttfunc.count_dict(dict_user) #count the freq\n",
    "dict_user_count_ans = pttfunc.count_dict(dict_user_ans) #count the freq for ans(test)\n",
    "print '--'\n",
    "print dict_user_count.values()[0]\n",
    "for k,v in dict_user_count.values()[0].iteritems():\n",
    "    print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## count all using words freq, preparing for generating sw_list \n",
    "count_all = Counter()\n",
    "for v in dict_user_count.values():\n",
    "    count_all += Counter(v)\n",
    "\n",
    "from collections import OrderedDict\n",
    "dict_all_count = OrderedDict(sorted(dict(count_all).items(), key=lambda t: t[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7842\n",
      "的 2076\n",
      "! 2066\n",
      "了 1246\n",
      "， 1054\n",
      "是 947\n",
      "~ 877\n",
      "? 860\n",
      "= 849\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for k,v in dict_all_count.iteritems():\n",
    "    i+=1\n",
    "    if i == 10:\n",
    "        break\n",
    "    print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total word 11827\n",
      "stop word 302\n",
      "rare word 7195\n",
      "num_word: 1 \t152\n",
      "num_word: 2 \t139\n",
      "num_word: 3 \t8\n",
      "num_word: 4 \t2\n",
      "num_word: 5 \t1\n",
      "302\n"
     ]
    }
   ],
   "source": [
    "##set threshold to generate stop words\n",
    "# with open('/Users/joekaojoekao/PycharmProjects/push/github/gossiping_push_jieba_freq_all_sorted_json.txt', 'rb') as fout:\n",
    "#     ptt_pushes_freq_all_sorted = json.load(fout)\n",
    "#     fout.close()\n",
    "# word = ptt_pushes_freq_all_sorted.keys()\n",
    "\n",
    "word = dict_all_count.keys()\n",
    "W_PERCENT = 0.025 #0.025\n",
    "## setting for stopword & rareword percentage\n",
    "stopwords = [x for x in word if dict_all_count[x] >= dict_all_count[word[int(len(word) * W_PERCENT)]]]\n",
    "rarewords = [x for x in word if dict_all_count[x] <= dict_all_count[word[int(len(word) * (1-W_PERCENT))]]] #0.975\n",
    "\n",
    "## stop word list\n",
    "sw_list = [x for x in stopwords] \n",
    "## rare word list\n",
    "rw_list = [x for x in rarewords] \n",
    "print 'total word', len(word)\n",
    "print 'stop word', len(sw_list)\n",
    "print 'rare word', len(rw_list)\n",
    "\n",
    "\n",
    "sw_count_dict = {}\n",
    "for w in sw_list:\n",
    "    sw_count_dict.setdefault(len(w),[]).append(w)\n",
    "\n",
    "\n",
    "K_NUMWORD = 6\n",
    "selected_sw = []\n",
    "for k in sw_count_dict.keys()[0:K_NUMWORD]:\n",
    "    print 'num_word:',k,'\\t',len(sw_count_dict[k])\n",
    "    selected_sw += sw_count_dict[k]\n",
    "print len(selected_sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u' ', u'\\u7684', u'!', u'\\u4e86', u'\\uff0c', u'\\u662f', u'~', u'?', u'=', u'\\u6211']\n",
      "718\n",
      "44\n",
      "要 1\n",
      "崇拜 1\n",
      "屌 1\n",
      "他們 1\n",
      "打 1\n",
      "喔 2\n",
      "Push 1\n",
      "可怕 1\n",
      "真的 1\n",
      "堅持下去 1\n",
      "! 2\n",
      "  2\n",
      "一定 1\n",
      "不要 3\n",
      "難過 1\n",
      "菁英 1\n",
      "XDDDDDDDD 1\n",
      "靠北 1\n",
      "好 3\n",
      "灶神 1\n",
      "=================\n",
      "！ 1\n",
      "休想 1\n",
      "的 3\n",
      "了 1\n",
      "謝謝 1\n",
      "很 1\n",
      "變 1\n",
      "小 1\n",
      "他們 1\n",
      "太扯 1\n",
      "這 1\n",
      "可怕 1\n",
      "真的 1\n",
      "! 5\n",
      "  3\n",
      "重要 1\n",
      "感人 1\n",
      "這樣 1\n",
      "馬 1\n",
      "就 1\n",
      "高調 3\n",
      "政商 1\n",
      "為 2\n",
      "非常 1\n",
      "好好 1\n",
      "這篇 1\n",
      "鋪路 1\n",
      "生命 1\n",
      "扯 1\n",
      "所欲 1\n",
      "不要臉 1\n",
      "有錢 1\n"
     ]
    }
   ],
   "source": [
    "print selected_sw[0:10]\n",
    "print len(dict_user_count)\n",
    "\n",
    "print sum([len(x) for x in dict_user_count[user_list[0]]])\n",
    "for k,v in dict_user_count[user_list[0]].iteritems():\n",
    "    print k,v\n",
    "#print dict_user[user_list[0]]\n",
    "print '================='\n",
    "for k,v in dict_user_count_ans[user_list[200]].iteritems():\n",
    "    print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n",
      "302\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "general_vec = {}\n",
    "for uid in user_list: # for each user id\n",
    "    user_len = sum([len(x) for x in dict_user_count[uid]]) #total word freq\n",
    "    #print sum(v.values())\n",
    "    if user_len > 0:\n",
    "        #vec = [jvc_grams_count[idx].get(w, 0) for w in new_sw_list] #stopword without function words\n",
    "        \n",
    "        vec = [dict_user_count[uid].get(w, 0) for w in selected_sw]\n",
    "        g_vec = [float(x) / user_len for x in vec]\n",
    "        general_vec[uid] = g_vec\n",
    "        \n",
    "\n",
    "general_vec_ans = {}\n",
    "for uid in user_list: # for each user id\n",
    "    user_len = sum([len(x) for x in dict_user_count_ans[uid]]) #total word freq\n",
    "    #print sum(v.values())\n",
    "    if user_len > 0:\n",
    "        #vec = [jvc_grams_count[idx].get(w, 0) for w in new_sw_list] #stopword without function words\n",
    "        \n",
    "        vec = [dict_user_count_ans[uid].get(w, 0) for w in selected_sw]\n",
    "        g_vec = [float(x) / user_len for x in vec]\n",
    "        general_vec_ans[uid] = g_vec\n",
    "\n",
    "print len(general_vec[user_list[0]])\n",
    "print len(general_vec_ans[user_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#play with all comb\n",
    "\n",
    "#import combination as gb\n",
    "import pttfunc\n",
    "#comb = gb.getCombination(len(user_list))\n",
    "\n",
    "##calculate similarity for each user pair\n",
    "\n",
    "sim_list = np.array((0.0, 0.0, 0.0))\n",
    "\n",
    "# for i, j in comb:\n",
    "#     wj_sw = pttfunc.weighted_jaccard(general_vec[user_list[i]], general_vec_ans[user_list[j]])\n",
    "#     #sim_list = np.append(sim_list, np.array((k1, k2, wj_sw), dtype=mtype))\n",
    "#     sim_list = np.vstack((sim_list, np.array((round(float(i),1), round(float(j),1), wj_sw))))\n",
    "\n",
    "for i in xrange(len(user_list)):\n",
    "    for j in xrange(len(user_list)):\n",
    "        wj_sw = pttfunc.weighted_jaccard(general_vec[user_list[i]], general_vec_ans[user_list[j]])\n",
    "        sim_list = np.vstack((sim_list, np.array((round(float(i),1), round(float(j),1), wj_sw))))\n",
    "\n",
    "\n",
    "\n",
    "sim_list = sim_list[1:]\n",
    "sim_list = sim_list[sim_list[:,2].argsort()]\n",
    "sim_list = sim_list[::-1]\n",
    "\n",
    "\n",
    "\n",
    "user_sim_list = []\n",
    "for i, j, sim in sim_list:\n",
    "    user_sim_list.append((user_list[int(i)], user_list[int(j)] + 'ANS', sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n"
     ]
    }
   ],
   "source": [
    "print len([x for x in user_sim_list if x[0] in x[1] and x[0] != x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'user_sim_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-c90e0771baf2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_sim_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'user_sim_list' is not defined"
     ]
    }
   ],
   "source": [
    "#evaluating (using interact later?)\n",
    "from IPython.html.widgets import interact\n",
    "def evaluate(x):\n",
    "    a = 0\n",
    "    for i,j,sim in user_sim_list:\n",
    "        if i in j and sim >= x:\n",
    "            a+=1\n",
    "    b = len(user_list)\n",
    "    print float(a) / b\n",
    "interact(evaluate, x=(0.0,1.0,0.01));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-75f36555f31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msim_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mwj_sw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpttfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted_jaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneral_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneral_vec_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#sim_list = np.append(sim_list, np.array((k1, k2, wj_sw), dtype=mtype))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#play with same(uncover ans)\n",
    "\n",
    "#import combination as gb\n",
    "import pttfunc\n",
    "#comb = gb.getCombination(len(user_list))\n",
    "\n",
    "##calculate similarity for each user pair\n",
    "\n",
    "sim_list = np.array((0.0))\n",
    "for i in xrange(len(user_list)):\n",
    "    wj_sw = pttfunc.weighted_jaccard(general_vec[user_list[i]], general_vec_ans[user_list[i]])\n",
    "    #sim_list = np.append(sim_list, np.array((k1, k2, wj_sw), dtype=mtype))\n",
    "    sim_list = np.vstack((sim_list, np.array(wj_sw))) ##here without np.array can save more\n",
    "    #sim_list = np.vstack((sim_list, np.array((round(float(idx1),1), round(float(idx2),1), wj_sw))))\n",
    "\n",
    "\n",
    "##generate user pushes and sim file\n",
    "\n",
    "\n",
    "\n",
    "sim_list = sim_list[1:]\n",
    "sim_list = sim_list[sim_list[:,0].argsort()]\n",
    "sim_list = sim_list[::-1]\n",
    "\n",
    "\n",
    "user_sim_list = []\n",
    "for i, sim in enumerate(sim_list):\n",
    "    user_sim_list.append((user_list[i], sim[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('heavenkghs', 0.72270742358078588), ('nysky', 0.65044247787610621), ('quiet113', 0.51063829787234039), ('john2557', 0.50720774633471588), ('duo0518', 0.5), ('tienhun', 0.5), ('joyjack', 0.5), ('vm9487', 0.5), ('aftersilence', 0.5), ('lingon', 0.5), ('toshizo', 0.5), ('yuminlin', 0.5), ('fhuocrkt', 0.5), ('theropod', 0.5), ('kkchen', 0.5), ('emptie', 0.5), ('h3178378', 0.49999999999999989), ('zxc12385', 0.4900822447992258), ('Amelie27', 0.47565871596774717), ('buddygirl', 0.4705882352941177), ('chiang017', 0.45644059014632715), ('fromwilda', 0.45591535663383564), ('carters', 0.45086011051000141), ('Magicwind', 0.44101074404853841), ('glory5566', 0.43087960802613168), ('feather9298', 0.43010752688172044), ('fjdkqp', 0.42379171957547646), ('cojinyu', 0.42124542124542175), ('gayya152535', 0.41593695271453596), ('hnrywang', 0.41342385333136589), ('bugya', 0.40913233452860631), ('JeanSijhih', 0.40572795195451883), ('joyjcc', 0.40330088870080416), ('jeffl0402', 0.39795177154614764), ('Valerie06', 0.3958859813592025), ('SpadeR', 0.39076105514768633), ('cloud0528', 0.38590604026845643), ('xup654vu06', 0.38540435704298387), ('kindless', 0.37774408301547024), ('mylife001', 0.3756708407871201), ('minnie', 0.37548240660874843), ('ronanhuang', 0.35671497584541018), ('tako0988', 0.35062006764374309), ('treiss', 0.34975488825514001), ('asami', 0.34848484848484845), ('mineko', 0.34632034632034631), ('dayoa', 0.34523036988968236), ('akaihuang', 0.34482758620689669), ('sigh0602', 0.34339753491157793), ('wolfking623', 0.34119187950229252), ('koreapig5566', 0.34074891217748376), ('lachesis1980', 0.33726188844730715), ('handsomecat', 0.33435897435897377), ('JCS15', 0.33333333333333337), ('caffeine34ko', 0.33333333333333337), ('pprisa', 0.33333333333333331), ('Nick7777', 0.33304652578120114), ('Voldemar', 0.33287706234486797), ('samuelcdf', 0.33088235294117646), ('jaguars33', 0.33073709859890393), ('chx64', 0.32812499999999994), ('otom', 0.32480356025311208), ('hiro1221', 0.32255456750202133), ('hyde7015', 0.32187314759928909), ('wxtab019', 0.32035230746833576), ('deleteBB', 0.32013189904649941), ('WhyNoSmoke', 0.31818181818181812), ('lovemelynn', 0.31658914728682203), ('straight0711', 0.31553816046966732), ('allen5339', 0.31019424906742699), ('q152134', 0.30756578947368429), ('Sugiros', 0.30726761171970463), ('ursula141885', 0.30244572684803472), ('Monchestnut', 0.30185497470489031), ('captainlee', 0.30128277897604738), ('hoka777', 0.30008140309331799), ('chind', 0.29949189812343929), ('kaorucyc', 0.29924963199655391), ('surot', 0.29893867924528283), ('TheMiserable', 0.2975722667815045), ('motorolla', 0.2933130390664635), ('aadm', 0.29281767955801108), ('benson', 0.29115053017540388), ('colan8', 0.29022177143013805), ('oscar1982law', 0.28695521326365819), ('a0913', 0.2857142857142857), ('emilyluvsptt', 0.28155339805825286), ('Vipasyin', 0.28079834824501054), ('ABC9D', 0.27990430622009588), ('w3160828', 0.27980535279805369), ('cat5672', 0.27908714647045302), ('queue', 0.27856025039123605), ('gogogo12321', 0.27641889533961456), ('kevinptt', 0.27592592592592585), ('cancer0708', 0.27420077681505811), ('robertchun', 0.27355854711709426), ('neo77', 0.27196452497926382), ('jennywalk', 0.27010519172039349), ('YesGG', 0.26950354609929078), ('ALLYJJ2599', 0.26920379349251339)]\n"
     ]
    }
   ],
   "source": [
    "print user_sim_list[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#sel_sim = [(x[0], x[1], x[2]) for x in sim_list if x[2] >= AVG_3SD]\n",
    "#sel_sim = [(x[0], x[1], x[2]) for x in sim_list]\n",
    "with open('/Users/joekaojoekao/PycharmProjects/push/github/cv_result/1000_1.txt', 'wb') as fout1:\n",
    "    for sim in user_sim_list:\n",
    "        line = sim[0] + ',' + str(sim[1]) +'\\n'\n",
    "        fout1.write(line.encode('utf-8'))\n",
    "fout1.close()\n",
    "\n",
    "# with open('/Users/joekaojoekao/PycharmProjects/push/github/visualized/select_pushes1000_' + str(n+1) + '.txt', 'wb') as fout2:\n",
    "#     for k in sel_user:\n",
    "#         for v in new_pushes[k]:\n",
    "#             if k == '':\n",
    "#                 continue\n",
    "#             line = k + '\\t' + v +'\\n'\n",
    "#             fout2.write(line.encode('utf-8'))\n",
    "# fout2.close()\n",
    "\n",
    "# print n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
